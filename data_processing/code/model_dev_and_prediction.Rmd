---
title: "model_dev_and_prediction"
author: "Valentin"
date: "`r Sys.Date()`"
output: 
  html_document:
      self_contained: false
---

# Set up and inputs
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

library(aws.s3)
aws.signature::use_credentials()
Sys.setenv("AWS_DEFAULT_REGION" = "eu-west-1")


library(tidyverse)
library(sf)
library(readxl)
library(xlsx)
library(stringr)
library(DescTools)
library(rnaturalearth)
library(ggpubr)
library(units)
library(scales)
library(kableExtra)
library(here)
library(tictoc)
library(readstata13)
library(sjmisc)
library(terra) # put it after {raster} such that it superceeds homonym functions. 
library(exactextractr)
library(stars)
library(pals)
library(modelsummary) # necessary to load it after DescTools

# ML libraries
library(ranger)
library(parsnip)
library(xgboost)
library(pROC)
library(yardstick)
library(CAST)
library(caret)

library(familiar)

# and packages required but some uses of familiar: 
library(microbenchmark)
library(glmnet)
library(fastcluster)
library(praznik)
library(power.transform)
library(isotree)
library(laGP)
library(harmonicmeanp)
library(mboost)

set.seed(8888)

# install.packages("https://cran.r-project.org/src/contrib/Archive/isotree/isotree_0.5.5.tar.gz",
#                  repos = NULL, 
#                  type = "source")

dir.create(here("temp_data", "model", "caret", "stage_1"), recursive = TRUE)
dir.create(here("temp_data", "model", "caret", "stage_2"), recursive = TRUE)

# These are were summon_familiar will write its outputs
dir.create(here("temp_data", "model", "familiar", "stage_1"), recursive = TRUE)
dir.create(here("temp_data", "model", "familiar", "stage_2"), recursive = TRUE)

# And to save the predictions 
dir.create(here("temp_data", "model", "predictions", "stage_1"), recursive = TRUE)
dir.create(here("temp_data", "model", "predictions", "stage_2"), recursive = TRUE)

# This is to save some of the outputs from being overwritten subsequently (not really used currently). 
dir.create(here("outputs", "familiar", "stage_1", "performance"), recursive = TRUE)
dir.create(here("outputs", "familiar", "stage_1", "explanation_vimp"), recursive = TRUE)
dir.create(here("outputs", "familiar", "stage_1", "models"), recursive = TRUE)
dir.create(here("outputs", "familiar", "stage_2", "performance"), recursive = TRUE)
dir.create(here("outputs", "familiar", "stage_2", "explanation_vimp"), recursive = TRUE)
dir.create(here("outputs", "familiar", "stage_2", "models"), recursive = TRUE)

## Functions
# Trase palettes etc. for plots
source(here("code", "theme_trase.R"))

# load in particular the function fn_trader_to_group_names, str_trans, ... 
source(here("code", "USEFUL_STUFF_supplyshedproj.R"))

# use the projected CRS used by BNETD for their 2020 land use map. 
civ_crs <- 32630

MODEL_RESOLUTION_KM = 4
cell_area_ha =(100*MODEL_RESOLUTION_KM^2)

xlabs = c(-8, -6, -4)
ylabs = c(5, 7, 9)

## Assets

coopbsy = read.csv(file = here("temp_data/private_IC2B/IC2B_v2_coop_bs_year.csv"))
coopbs22 = coopbsy %>% filter(YEAR == 2022)

consol = readRDS(here("temp_data", "actual_links_consolidated.Rdata"))

cells = readRDS(here("temp_data", "prepared_main_dataset", paste0("cell_", MODEL_RESOLUTION_KM, "km.Rdata"))) 

links = readRDS(here("temp_data", "prepared_main_dataset", paste0("cell_links_", MODEL_RESOLUTION_KM, "km.Rdata")))

departements <- read_sf(here("input_data/s3/CIV_DEPARTEMENTS.geojson"))
departements = 
  st_transform(departements, crs = civ_crs)

```

## Pre-process columns
```{r}
cells = 
  cells %>% 
  rename(CELL_PROP_COOP_STATUS_COOPCA = `CELL_PROP_COOP_STATUS_COOP-CA`, 
         CELL_PROP_1_NEAREST_COOP_STATUS_COOPCA = `CELL_PROP_1_NEAREST_COOP_STATUS_COOP-CA`, 
         CELL_PROP_5_NEAREST_COOP_STATUS_COOPCA = `CELL_PROP_5_NEAREST_COOP_STATUS_COOP-CA`) %>% 
  # this is just for descriptives a priori
  mutate(CELL_2ND_STAGE_ONLY = CELL_ANY_ACTUAL_COOP_LINK & !CELL_VOLUME_OBSERVED, 
         CELL_NO_ACTUAL_LINK_DATA = CELL_ONLY_VIRTUAL_LINK | (!CELL_ONLY_VIRTUAL_LINK & 
                                                              CELL_ACTUAL_ONLYOTHER_LINK & 
                                                              !CELL_VOLUME_OBSERVED))

links = 
  links %>% 
  rename(COOP_STATUS_COOPCA = `COOP_STATUS_COOP-CA`,
         COOP_DISTRICT_SAN_PEDRO = `COOP_DISTRICT_SAN-PEDRO`,
         COOP_DISTRICT_GRAND_LAHOU = `COOP_DISTRICT_GRAND-LAHOU`,
         COOP_DISTRICT_YAKASSE_ATTOBROU = `COOP_DISTRICT_YAKASSE-ATTOBROU`,
         COOP_DISTRICT_ZOUAN_HOUNIEN = `COOP_DISTRICT_ZOUAN-HOUNIEN`,
         COOP_DISTRICT_KOUN_FAO = `COOP_DISTRICT_KOUN-FAO`,
         COOP_DISTRICT_GRAND_BASSAM = `COOP_DISTRICT_GRAND-BASSAM`, 
         COOP_DISTRICT_MBATTO = `COOP_DISTRICT_M'BATTO`)

# Make target a factor
links = 
  links %>% 
  mutate(LINK_IS_ACTUAL_COOP_class = factor(if_else(LINK_IS_ACTUAL_COOP, "Actual_links", "Virtual_links"), 
                                               levels = c("Virtual_links", "Actual_links"))) 

# Make COOP (and not Buying station) ID: 
links = 
  links %>% 
  mutate(LINK_ACTUAL_COOP_ID = gsub("_BS.*", "", LINK_ACTUAL_COOP_BS_ID), 
         LINK_POTENTIAL_COOP_ID = gsub("_BS.*", "", LINK_POTENTIAL_COOP_BS_ID))


# Productive & prospective cells

cells = 
  cells %>% 
  mutate(
    # This one could be moved to Outputs.Rmd
    CELL_PRODUCTION_STATUS = if_else(CELL_COCOA_HA < 80, 
                                          "PROSPECTIVE", 
                                          "PRODUCTIVE"),
   # also compute the share of area under cocoa use, to use below
   CELL_COCOA_SHARE = CELL_COCOA_HA / 1600, 
   # and of impossible land
   CELL_IMPOSSIBLE_SHARE = CELL_IMPOSSIBLE_HA / 1600 
 )
table(cells$CELL_PRODUCTION_STATUS)

links = 
  links %>% 
  left_join(
    cells %>% select(CELL_PRODUCTION_STATUS, CELL_COCOA_SHARE, CELL_IMPOSSIBLE_SHARE, CELL_ID), 
    by = "CELL_ID")

# Distribution of cocoa extent in cells where we know there are cocoa farms 
cells_actual = 
  cells %>% 
  filter(CELL_ACTUAL_LINK) 

cells_actual$CELL_COCOA_HA %>% summary() # It goes as low as 2 ha, but has on average 443 ha. 
cells_actual$CELL_COCOA_HA %>%quantile(probs = seq(0.01,0.1,0.01))

# 5% of the cells with actual links is a good threshold, because the cocoa area quantile corresponds to 5% of a cell area
# (i.e., 80ha, since one cell is 1600ha)


```




## Development data

### Remove some cells and links
```{r}
# BASED ON LU 

# Remove cells with virtually no cocoa and no space for cocoa to grow 
summary(cells$CELL_COCOA_HA)
summary(cells$CELL_IMPOSSIBLE_HA)

# Very few cells have more than 80% of their area impossible for cocoa expansion. 
# Consequently, most cells are possibly of interest to our study, either because they have cocoa, or because 
# they have some space for cocoa to expand. 
cells = 
  cells %>%  
  filter(!(CELL_COCOA_SHARE < 0.01 & CELL_IMPOSSIBLE_SHARE > 0.8))

links = 
  links %>% 
  filter(!(CELL_COCOA_SHARE < 0.01 & CELL_IMPOSSIBLE_SHARE > 0.8))


# FEW EXTRA-TERRITORIAL LEFT
# Remove cells with no district (very few since we already removed cells outside inland territory in data preparation)
# cells %>% filter(is.na(CELL_DISTRICT_NAME)) %>% pull(SPLIT) %>% unique()
# cells %>% filter(is.na(CELL_DISTRICT_NAME)) %>% nrow()
cells = 
  cells %>% 
  # Remove the few cells that still fall in no district 
  filter(!is.na(CELL_DISTRICT_NAME)) 

links = 
  links %>% 
  # Remove the few cells that still fall in no district 
  filter(!is.na(CELL_DISTRICT_NAME))
  
# LINKS NOT TO TRAIN NOR PREDICT 
links =
  links %>%
  # Remove links with non-IC2B coops or with other buyers, 
  # because they would count as FALSE on LINK_IS_ACTUAL_COOP, the target var, while not being exactly what we are after
  filter(!LINK_IS_ACTUAL_OTHER) %>% 
  # Remove empty links that only represent cells from where no coop is reachable. 
  # We are not interested in describing, learning from, or predicting in these cells. We will recollect them post-estimation
  filter(!CELL_NO_POTENTIAL_LINK)

stopifnot(links %>% 
            filter(!LINK_IS_VIRTUAL) %>% nrow() == sum(links$LINK_IS_ACTUAL_COOP))

```

### Under-sample virtual links
```{r}
links_us = 
  links %>% 
  filter(!LINK_POSSIBLE_FALSENEG) %>% 
  filter(LINK_TO_KEEP_TO_US_VIRTUAL) # this is only TRUE currently. 
```

### Extract development sets
Any processing on explanatory features' values should be made before this step so it is done once for all the data
```{r}
cells = 
  cells %>% 
  mutate(SPLIT = if_else(CELL_VOLUME_OBSERVED, "Development set", "No data")) 

stg1_development =
  cells %>% filter(SPLIT == "Development set") 

links_us = 
  links_us %>% 
  mutate(SPLIT = if_else(CELL_ACTUAL_LINK & !CELL_ACTUAL_ONLYOTHER_LINK, "Development set", "No data")) 

stg2_development =
  links_us %>%
  filter(SPLIT == "Development set") 

cells_stg2_development =
  stg2_development %>%
  distinct(CELL_ID, .keep_all = TRUE) %>% 
  select(starts_with("CELL_"))

```



# INPUT DESCRIPTIVES 

## Observed links data

### Table 
```{r}
# Filter data
jrcdata <- consol %>% filter(grepl("JRC", PRO_ID))
scdata <- consol %>% filter(grepl("SUSTAINCOCOA", PRO_ID))
cargilldata <- consol %>% filter(grepl("CARGILL", PRO_ID))

paste0("There are ", 
       nrow(jrcdata), " farmer-buyer links, between ",
       length(unique(jrcdata$PRO_ID)), " farmers located in ",
       length(unique(jrcdata$PRO_VILLAGE_NAME)), " villages and ",
       nrow(filter(jrcdata, BUYER_IS_COOP)) + nrow(filter(jrcdata, !BUYER_IS_COOP)), " buyers. ",
       nrow(filter(jrcdata, BUYER_IS_COOP)), " links are with cooperatives, ", 
       nrow(filter(jrcdata, !is.na(COOP_BS_ID))), " of which are links with IC2B, and ", 
       nrow(filter(jrcdata, !BUYER_IS_COOP)), " are links with another kind of buyers. ",
       nrow(filter(jrcdata, !is.na(LINK_VOLUME_KG))), " links have clean volume information."
)

paste0("There are ", 
       nrow(scdata), " farmer-buyer links, between ",
       length(unique(scdata$PRO_ID)), " farmers located in ",
       length(unique(scdata$PRO_VILLAGE_NAME)), " villages and ",
       nrow(filter(scdata, BUYER_IS_COOP)) + nrow(filter(scdata, !BUYER_IS_COOP)), " buyers. ",
       nrow(filter(scdata, BUYER_IS_COOP)), " links are with cooperatives, ", 
       nrow(filter(scdata, !is.na(COOP_BS_ID))), " of which are links with IC2B, and ", 
       nrow(filter(scdata, !BUYER_IS_COOP)), " are links with another kind of buyers. ",
       nrow(filter(scdata, !is.na(LINK_VOLUME_KG))), " links have clean volume information."
)

paste0("There are ", 
       nrow(cargilldata), " farmer-buyer links, between ",
       length(unique(cargilldata$PRO_ID)), " farmers located in ",
       length(unique(cargilldata$PRO_VILLAGE_NAME)), " villages and ",
       nrow(filter(cargilldata, BUYER_IS_COOP)) + nrow(filter(cargilldata, !BUYER_IS_COOP)), " buyers. ",
       nrow(filter(cargilldata, BUYER_IS_COOP)), " links are with cooperatives, ", 
       nrow(filter(cargilldata, !is.na(COOP_BS_ID))), " of which are links with IC2B, and ", 
       nrow(filter(cargilldata, !BUYER_IS_COOP)), " are links with another kind of buyers. ",
       nrow(filter(cargilldata, !is.na(LINK_VOLUME_KG))), " links have clean volume information."
)


# Create summary data frames
summary_data <- data.frame(
Metric = c("Source", 
            "Year", 
            "Spatial information", 
            "Volume information", 
            "Villages", 
            "Farmers", 
            "Farmer-Buyer Links", 
                 "With cooperatives", 
                 "With other buyers", 
            "Buyers", 
                 "Cooperatives", 
                 "Other buyers"
              ),
  JRC = c(
          "JRC", "2019", "Farm point", "Yes",
          length(unique(jrcdata$PRO_VILLAGE_NAME)), 
          length(unique(jrcdata$PRO_ID)), 
          nrow(jrcdata), 
          nrow(filter(jrcdata, !is.na(COOP_BS_ID))), 
          nrow(filter(jrcdata, !BUYER_IS_COOP)), 
          length(unique(jrcdata$BUYER_ACTUAL_LINK_ID)),
          length(unique(pull(filter(jrcdata, !is.na(COOP_BS_ID)), BUYER_ACTUAL_LINK_ID))),
          length(unique(pull(filter(jrcdata, !BUYER_IS_COOP), BUYER_ACTUAL_LINK_ID)))
          ),
  SC = c(
          "Sustain-Cocoa project", "2022", "Village point", "Yes",
          length(unique(scdata$PRO_VILLAGE_NAME)), 
          length(unique(scdata$PRO_ID)), 
          nrow(scdata), 
          nrow(filter(scdata, !is.na(COOP_BS_ID))), 
          nrow(filter(scdata, !BUYER_IS_COOP)), 
          length(unique(scdata$BUYER_ACTUAL_LINK_ID)), 
          length(unique(pull(filter(scdata, !is.na(COOP_BS_ID)), BUYER_ACTUAL_LINK_ID))),
          "Unknown"
          ),
  CARGILL = c(
          "Public repository", "2019", "Farm polygon", "No",
          "Unknown", 
          length(unique(cargilldata$PRO_ID)), 
          nrow(cargilldata), 
          nrow(filter(cargilldata, !is.na(COOP_BS_ID))), 
          nrow(filter(cargilldata, !BUYER_IS_COOP)), 
          length(unique(cargilldata$BUYER_ACTUAL_LINK_ID)), 
          length(unique(pull(filter(cargilldata, !is.na(COOP_BS_ID)), BUYER_ACTUAL_LINK_ID))),
          length(unique(pull(filter(cargilldata, !BUYER_IS_COOP), BUYER_ACTUAL_LINK_ID)))
          )
) 
colnames(summary_data) = c(" ", "JRC Data", "SC Data", "Cargill Data")
  
# Create table with kableExtra and add indentation
table <- summary_data %>%
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "responsive")) %>%
  
  row_spec(8, extra_css = "padding-left: 20px;") %>%
  row_spec(9, extra_css = "padding-left: 20px;") %>%
  row_spec(11, extra_css = "padding-left: 20px;") %>%
  row_spec(12, extra_css = "padding-left: 20px;")

table

save_kable(table, here("outputs", "input_data_descriptives", "Observed_links_table.png"))

```


### Map 
```{r}
consol = 
  consol %>% 
  mutate(Source = case_when(grepl("JRC", PRO_ID) ~ "JRC", 
                            grepl("SUSTAINCOCOA", PRO_ID) ~ "SC", 
                            grepl("CARGILL", PRO_ID) ~ "CARGILL", 
                            TRUE ~ "OTHER"))

consol_farm_sf = 
  consol %>% 
  st_as_sf(coords = c("PRO_LONGITUDE", "PRO_LATITUDE"), crs = 4326, remove = FALSE)

consol_coop_sf = 
  consol %>% 
  filter(!is.na(BUYER_LONGITUDE) & BUYER_IS_COOP) %>% # This excludes other buyers
  distinct(COOP_BS_ID, .keep_all = TRUE) %>% 
  st_as_sf(coords = c("BUYER_LONGITUDE", "BUYER_LATITUDE"), crs = 4326, remove = FALSE) 

unlinked_coopbs_sf = 
  coopbs22 %>% 
  filter(!is.na(LONGITUDE) & !COOP_BS_ID %in% consol_coop_sf$COOP_BS_ID) %>% # This excludes coops already in observed links data
  distinct(COOP_BS_ID, .keep_all = TRUE) %>% 
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs = 4326)

coops_toplot = 
  rbind(
    consol_coop_sf %>% 
      mutate(`Cooperative with observed link` = "Yes") %>% 
      select(Source, `Cooperative with observed link`, geometry),
    unlinked_coopbs_sf %>% 
      mutate(
        Source = NA,
        `Cooperative with observed link` = "No") %>% 
      select(Source, `Cooperative with observed link`, geometry)
  ) %>% 
  mutate(`Cooperative with observed link` = factor(`Cooperative with observed link`, 
                                                   levels = c("Yes", "No")))

# Function to create a line geometry
create_line <- function(b_lon, b_lat, p_lon, p_lat) {
  st_linestring(matrix(c(b_lon, b_lat, 
                         p_lon, p_lat), 
                       ncol = 2, 
                       byrow = TRUE))
}

# Apply the function to each row
df = consol %>% 
  # Exclude other buyers than IC2B (thus geolocalised) coops. 
  filter(!is.na(BUYER_LONGITUDE) & BUYER_IS_COOP) 

df = df %>% 
  mutate(geometry = mapply(create_line, 
                      BUYER_LONGITUDE, BUYER_LATITUDE, 
                      PRO_LONGITUDE, PRO_LATITUDE, 
                      SIMPLIFY = FALSE)
  )

# Convert to sf object
df <- st_sf(df, crs = 4326) %>% 
  st_transform(civ_crs) %>% 
  arrange(Source)


map_links = 
  ggplot() +
    geom_sf(data = df, aes(col = Source), size = 5) + #, shape = 15
    geom_sf(data = coops_toplot, aes(col = Source, size = `Cooperative with observed link`)) +
    
    scale_colour_manual(
        values = c("skyblue", "purple", "darkgreen"), 
        na.value = "black") +

    scale_size_manual(
      values = c("Yes" = 1, 
                 "No" = 0.1)
    ) +
  geom_sf(data = departements, fill = "transparent", col = "black") +
  
  theme_bw() + 
  theme(legend.key.size = unit(1, "cm")) +
    scale_x_continuous(breaks = xlabs, labels = paste0(xlabs,'°W')) +
    scale_y_continuous(breaks = ylabs, labels = paste0(ylabs,'°N'))
 
map_links 

ggsave(
  plot = map_links, 
  filename = "map_links.png",
  path = here("outputs", "input_data_descriptives"), 
  width = 25, 
  height = 20,
  units = "cm")

# ggplot() +
#     geom_sf(data = coopbs_omit_sf, col = "red", size = 2) +
#   geom_sf(data = departements, fill = "transparent", col = "black") +
# 
#   theme_bw() +
#   theme(legend.key.size = unit(1, "cm")) +
#     scale_x_continuous(breaks = xlabs, labels = paste0(xlabs,'°W')) +
#     scale_y_continuous(breaks = ylabs, labels = paste0(ylabs,'°N'))

```


## Cells data 

### Structure
```{r}
# How many cells with actual links
# cells %>% 
#   select(!starts_with("CELL_PROP") & !starts_with("CELL_COUNT")) %>% 
#   datasummary_skim()

# nocat = 
#   cells %>%
#   filter(!CELL_NO_POTENTIAL_LINK & !CELL_NO_ACTUAL_LINK_DATA & !CELL_2ND_STAGE_ONLY & !CELL_VOLUME_OBSERVED) %>% 
#   View()
# cell_ids_check = nocat$CELL_ID
# links %>% filter(CELL_ID %in% cell_ids_check) %>% 
#   pull(CELL_ACTUAL_ONLYOTHER_LINK) %>% summary()

# export
(datasummary(N + Percent()  ~ 
              (`No buying station within 72 km` = (CELL_NO_POTENTIAL_LINK==T)) + 
              (`No observed link` = (CELL_NO_ACTUAL_LINK_DATA==T)) + 
              (`Observed link data for 2nd stage only` = (CELL_2ND_STAGE_ONLY==T)) + 
              (`Observed link data for both stages` = (CELL_VOLUME_OBSERVED==T)) + 
              1, 
              data = cells,
              fmt = 1,
              align = "cccccc",
              output = here("outputs", "input_data_descriptives", paste0("cells_",MODEL_RESOLUTION_KM,"km_destat.png"))))
# Cells with actual link data for both stages have JRC or SC data on actual link existence, size and type of buyer (cooperative or other), that is representative for the whole cell. 

# ?tables::Heading

stg1_development %>% nrow()

```

The map on the information content of the Cells data is produced after model development, in order to add the AoA status.

The descriptive statistics on the cell-level features are computed in the Explanation section, 
together with other analyses on predictors, and after the making of the formula including all or most 
exogenous only predictors.   

Cell data balance tests
```{r}
# (datasummary_balance(~SPLIT, 
#                       data = cells_features_tobalance, 
#                       stars = TRUE,
#                       # title = "Summaries and balance tests on cell data sets to development and to predict the cell share of cooperative outlet", 
#                       notes = "'BS' stands for cooperative buying stations.", 
#                      output = here("outputs", "input_data_descriptives", "cells_balance.png")))        
```

### LU 
```{r}
(cells_stg2_development$CELL_COCOA_HA/cell_area_ha) %>% summary()
  
stg1_development %>% 
  select(Sample = SPLIT, 
          `Dense forest extent (ha)` = CELL_DENSEFOREST_HA,
          `other forests extent (ha)` = CELL_OTHERFORESTS_HA,
          `Cocoa extent (ha)` = CELL_COCOA_HA,
          `Coffee extent (ha)` = CELL_COFFEE_HA,
          `Rubber extent (ha)` = CELL_RUBBER_HA,
          `Palm extent (ha)` = CELL_PALM_HA,
          `Coconut extent (ha)` = CELL_COCONUT_HA,
          `Cashew extent (ha)` = CELL_CASHEW_HA,
          `Other agricultural extent (ha)` = CELL_OTHERAG_HA,
          `Settlements extent (ha)` = CELL_SETTLEMENT_HA,
          `Water, rock or infrastructure extent (ha)` = CELL_IMPOSSIBLE_HA
  ) %>% 
  datasummary_skim(output = here("outputs", "input_data_descriptives", paste0("stg1_",MODEL_RESOLUTION_KM,"km_features.html")))

```


## Links data

### Observed links 
This starts from links data, where no under-sampling has been applied (so the biased sampling towards coops is still in there). 
```{r}
obs_links_des = 
  links %>% 
  filter(LINK_IS_ACTUAL) %>% 
  mutate(LINK_SOURCE = case_when(
    grepl("CARGILL", PRO_ID) ~ "Cargill data",
    grepl("SUSTAINCOCOA", PRO_ID) ~ "SC data",
    grepl("JRC", PRO_ID) ~ "JRC data",
  ))

length(unique(na.omit(obs_links_des$LINK_ID_OTHERS)))

totbl = 
  obs_links_des %>% 
  summarise(.by = LINK_SOURCE,  
    # Number of 
    # Links
    `with coops` = length(unique(na.omit(LINK_ID_COOPS))), # if_else(BUYER_IS_COOP, LINK_ID, NA)
    `with others` = length(unique(na.omit(LINK_ID_OTHERS))), 
    # Farms
    `Farms` = length(unique(na.omit(PRO_ID))), 
    `Villages` = length(unique(na.omit(PRO_VILLAGE_NAME))), 
    # Buyers
    Buyers = length(unique(na.omit(BUYER_ID))),
    `IC2B coops` = length(unique(na.omit(LINK_ACTUAL_COOP_ID))),
    `IC2B buying stations` = length(unique(na.omit(LINK_ACTUAL_COOP_BS_ID))),
    `Not coops` = length(unique(na.omit(if_else(!BUYER_IS_COOP, BUYER_ID, NA))))
    
    )

totbl

```


### Balance tests in Links features
With differences between actual and/virtual in development. 
Alternatively, we could look at: 
- Only in actual 
- Only in all (potential)

```{r}
names(stg2_development)
stg2_features_tobalance_1 =
  stg2_development %>%
  mutate(across(where(is.logical), as.integer)) %>% 
  select(LINK_IS_ACTUAL_COOP_class, 
         LINK_DISTANCE_METERS,
         LINK_IS_WITH_1_NEAREST_COOPS,
         LINK_IS_WITH_5_NEAREST_COOPS,
         CELL_N_BS_WITHIN_DIST,
         CELL_N_COOP_IN_DPT, CELL_AVG_N_LICBUY_IN_DPT,
         CELL_COCOA_HA, CELL_SETTLEMENT_HA, CELL_IMPOSSIBLE_HA, CELL_TRI_MM)

datasummary_balance(~LINK_IS_ACTUAL_COOP_class, 
                    data = stg2_features_tobalance_1, 
                    output = here("outputs", "input_data_descriptives", paste0("stg2_",MODEL_RESOLUTION_KM,"km_features.png")))

stg2_features_tobalance_2 =
  stg2_development %>%
  mutate(across(where(is.logical), as.integer)) %>% 
  select(LINK_IS_ACTUAL_COOP_class,
         COOP_FARMERS, 
         COOP_N_KNOWN_BUYERS, COOP_N_KNOWN_BS,
         starts_with("COOP_STATUS_"), 
         COOP_CERTIFIED, COOP_RFA, COOP_UTZ, COOP_FT, 
         COOP_HAS_SSI, starts_with("COOP_SSI_"), 
         starts_with("COOP_BS_10KM_"))

datasummary_balance(~LINK_IS_ACTUAL_COOP_class, 
                    data = stg2_features_tobalance_2)

```


# MODEL DEVELOPMENT

## 1st stage
### Design & Formula
```{r}
# Experimental design 
exp_design = "bt(fs+mb,40)"

# Repository for familiar 1st stage 
# summon_familiar writes all it does in a repo. It returns nothing here.  
stage1_expdes_repo = here("temp_data", "model", "familiar", "stage_1", gsub(",","_",exp_design))
dir.create(stage1_expdes_repo)

anyNA(stg1_development)
# names(cells)
# anyNA(cells)
# stg1_development %>% names() %>% grep(~., pattern = "CELL_COUNT_", value = T)
# stg1_development %>% select(
#     contains("_HA") & contains("CELL_AVG"),
# ) %>% names() %>% grep(~., pattern = "CELL_AVG_", value = T)

stg1_allfeatures = 
  cells %>% 
  select(
    # Exclude all LU vars, on both cell and coop level, except for settlements. 
    (starts_with("CELL_AVG_") & !ends_with("_HA")) | 
    contains("SETTLEMENT")                         |
    starts_with("CELL_PROP_")                      | 
    starts_with("CELL_COUNT_"),
    # some corrections/additions
    -CELL_PROP_VOLUME_COOPS, -CELL_PROP_VOLUME_OTHERS,
    
    CELL_TRI_MM, CELL_N_BS_WITHIN_DIST, CELL_N_COOP_IN_DPT, CELL_MIN_DISTANCE_METERS, CELL_MIN_TRAVEL_METERS
  ) %>%
  names()

# Include coop-level features summarised at the 1 nearest, the 5 nearest and the whole-coop levels. This increases the simple fit performance from an OOB R2 of .17 (with only summaries at 5 nearest coop-level) to .24  names()  
  
# Restricted list of more exogenous features regarding the further applications of the model. 
# This excludes SSI and certification related variables, as well as the number of known buyers. 
stg1_exofeatures = 
  stg1_allfeatures %>% 
  grep(~., pattern = "DISTANCE|TRAVEL|N_BS_WITHIN|N_KNOWN_BS|N_COOP_IN|LICBUY|STATUS|_TRI|SETTLEMENT|COOP_FARMERS$", 
       value = TRUE) %>% 
  unique()

setdiff(stg1_allfeatures, stg1_exofeatures)

stg1_formula_allfeatures = as.formula(paste0("CELL_PROP_VOLUME_COOPS ~ ", paste0(stg1_allfeatures, collapse = " + ")))
stg1_mformula_exofeatures = as.formula(paste0("CELL_PROP_VOLUME_COOPS ~ ", paste0(stg1_exofeatures, collapse = " + ")))

```

The first stage has `r length(stg1_allfeatures)` potential features, `r length(stg1_exofeatures)` of which are exogenous to further applications. 

### Simple fit 
This is simple because it does not do feature selection nor optimize hyper-parameters.
```{r}
stg1_mfit = ranger(data = stg1_development, 
                   importance = 'permutation',
                   case.weights = "CELL_REPRESENTATIVITY_STD_WEIGHT",
                   formula = stg1_formula_allfeatures, 
                   seed = 8888
                   )
print(stg1_mfit)

stg1_mfit = ranger(data = stg1_development, 
                   importance = 'permutation',
                   case.weights = "CELL_REPRESENTATIVITY_STD_WEIGHT",
                   formula = stg1_mformula_exofeatures, 
                   seed = 8888
                   )
print(stg1_mfit)

```


### caret
```{r}
# 400 boostraps prend quand même ~1h+ ! 
model1_caret = 
  train(
    x = stg1_development %>% select(all_of(stg1_allfeatures)),
    y = stg1_development$CELL_PROP_VOLUME_COOPS, 
    method="rf", 
    importance=TRUE, 
    tuneLength=5,
    trControl=trainControl(method="boot632",number=400,savePredictions=T)
  )

saveRDS(model1_caret, 
        file = here("temp_data", "model", "caret", "stage_1", "allfeatures_rf_400boot632_5tuneL"))

model1_caret_xgb = 
  train(
    x = stg1_development %>% select(all_of(stg1_allfeatures)),
    y = stg1_development$CELL_PROP_VOLUME_COOPS, 
    method="xgbTree", 
    importance=TRUE, 
    tuneLength=5,
    trControl=trainControl(method="boot632",number=4,savePredictions=T)
  )

saveRDS(model1_caret_xgb, 
        file = here("temp_data", "model", "caret", "stage_1", "allfeatures_xgbtree_4boot632_5tuneL"))
```

Performance
```{r}
# That's the average across all the 500 trees
model1_caret$finalModel$mse %>% mean()
# But the ensemble's mse is averaged with weights equal to each tree's performance (or something)
model1_caret$finalModel

# And this is for all the 400 repetitions of the ensemble 
# It is quite worse and I am not sure why.
resamples <- model1_caret$resample
mean(resamples$RMSE^2)

sd(resamples$RMSE)

mean(resamples$Rsquared)
sd(resamples$Rsquared)

# For XGB
resample1_xgb = model1_caret_xgb$resample 

mean(resample1_xgb$RMSE^2)
sd(resample1_xgb$RMSE^2)
mean(resample1_xgb$Rsquared)
sd(resample1_xgb$Rsquared)



# This is to access performance metrics aggregated over resamples for different models 
resamps <- resamples(list(first_caret = model1_caret_xgb, first_caret2 = model1_caret))
summary(resamps)

```

### familiar
Doing feature ranking and hyper-parameter optimization
This is the model development. 

This is all handled by package familiar. 

For warm starts: 
precompute_data_assignment --> An experimentData object.
precompute_feature_info    --> An experimentData object.
precompute_vimp            --> An experimentData object.
(each does additional steps)

predict function like anywhere else. 
```{r}
# ?train_familiar
# ?theme_familiar
# ?summon_familiar
# ?as_familiar_data
# ?predict  

anyNA(stg1_development)


# let's go
summon_familiar(
  
  formula = stg1_formula_allfeatures,
  data = stg1_development %>% select(CELL_ID, CELL_PROP_VOLUME_COOPS, all_of(stg1_allfeatures)),
  experiment_dir = stage1_expdes_repo,
  sample_id_column = "CELL_ID",
  outcome_name = "Cooperative outlet share",
  outcome_column = "CELL_PROP_VOLUME_COOPS",
  outcome_type = "continuous",
  experimental_design = exp_design, #"fs + mb", #  # "cv(bt(fs,100) + mb, 3)",
  
  # Use bt because we have many features compared to the number of observations.  "The most practical application of bt is for repeating feature selection multiple times (e.g. bt(fs,50)+mb+ev), as this allows for aggregating variable importance and reducing the effect of random selection."

  # imbalance_correction_method = "random_undersampling", # do not specify, to avoid any kind of under-sampling, since we did it in external pre-processing.  
  parallel = TRUE,
  parallel_nr_cores = detectCores() - 1, 
  
  # PRE-PROCESSING ARGS
  # (not all "none" are the defaults)
  filter_method = "none", # no feature to be filtered in pre-processing
  transformation_method = "none", 
  normalisation_method = "none",
  cluster_method = "hclust", # the default. This is categorised in data processing, but it will affect feature selection. 
  # imputation_method does not matter bc we have no NA. 
  
  # FEATURE SELECTION & OPTIMIZATION 
  fs_method = "random_forest_ranger_permutation", # see https://cran.r-project.org/web/packages/familiar/vignettes/feature_selection_precompiled.html
  # fs_method_parameter = list("random_forest_ranger_permutation" = list()), # this would need to have this format, but let it unspecified, so that feature selection optimizes on ALL hyper-parameters. 
  # vimp_aggregation_method = "borda", # borda is the default. Check guidance to depart. 
  
  learner = "random_forest_ranger",
  # hyperparameter = list("ranger" = list()), #  "If no parameters are provided, sequential model-based optimisation is used to determine optimal hyperparameters."
  
  # EVALUATION INFERENCE
  # The default is "bootstrap_confidence_interval" or "bci", so we have to tell the model to do just quick point estimates where we don't care much about inference. Especially as bci can easily be queried in post-processing.  
  skip_evaluation_elements = c("feature_expressions", "feature_similarity", 
                               "fs_vimp",  "hyperparameters", "ice_data", 
                                "permutation_vimp", "univariate_analysis"), #"model_vimp", 
  
  # part of this list elements are useless now, since they are skipped by the above. 
  estimation_type = list("prediction_data" = "bci", "model_performance"="bci", 
                         "permutation_vimp" = "point", 
                         "ice_data"= "point", 
                         "auc_data" = "point", 
                         "decision_curve_analyis" = "point"), 
  # estimation_type = list("prediction_data" = "hybrid", "model_performance"="hybrid", 
  #                        "permutation_vimp" = "ensemble", 
  #                        "ice_data"= "ensemble", 
  #                        "auc_data" = "ensemble", 
  #                        "decision_curve_analyis" = "ensemble"), 
  confidence_level = 0.95, # the default. 
  detail_level = "hybrid" # the default. See evaluation vignette. 
)

```
The results folder outputed by summon_familiar is saved manually to different place, to protect it from being overwritten in a subsequent run of the above block. 



Several things to say: 


The relative squared error being lower than 1, the model still performs better than the mean predictor. 





The most important variables, across the ensemble of models, are: 
1/ the number of (CELL_COUNT_5_NEAREST_COOP_N_KNOWN_BS); 
2/ the road distance to the closest buying station (CELL_MIN_DISTANCE_METERS);
3/ the number of RFA farmers in the 5 nearest cooperatives (CELL_COUNT_5_NEAREST_COOP_FARMERS_RFA); 
4/ the cocoa extent in a 10km buffer around all the cooperatives located within ~70km (CELL_AVG_COOP_BS_10KM_COCOA_HA); 
5/ the number of buying stations within 70km (CELL_N_BS_WITHIN_DIST);
6/ the proportion of simplified coops in the 5 nearest cooperatives (CELL_PROP_5_NEAREST_COOP_STATUS_SCOOPS); 
7/ the proportion of sustainable sourcing initiatives in the 5 nearest cooperatives (CELL_PROP_5_NEAREST_COOP_HAS_SSI);

Now, let's see whether these features contribute to increase or decrease the cell's share of cooperative outlet.  


All important features positively explain the share of coop outlet, except the distance of the closest coop (which is expected), and the number of RFA farmers (which is surprising). 



## 2nd stage

### Formula
```{r}
stg2_development %>% names() %>% grep(~., pattern = "CELL_PROP_", value = T)
stg2_development %>% select(
     (ends_with("_HA"))
) %>% names() %>% grep(~., pattern = "CELL_AVG_", value = T)

stg2_allfeatures = 
  stg2_development %>% 
  select(
    # Do not include any LU var, on either cell or coop level, except for settlements. 
    # Do not include SSI-related vars either, because the development data is biased towards CCP, and thus ANY_SSI and not any other SSI. 
    # stg2_development %>% filter(grepl("CARGILL", PRO_ID)) %>% pull(COOP_SSI_CARGILL) %>% summary()
    
    # Cell level
    CELL_TRI_MM, CELL_SETTLEMENT_HA,
    
    # Topologic - i.e. other-link level
    CELL_N_BS_WITHIN_DIST, CELL_N_COOP_IN_DPT, CELL_AVG_N_LICBUY_IN_DPT, 
    # We could add cell level average/prop/count of nearest and potential coops, but they are not in the link data set currently. 
    # CELL_MIN_DISTANCE_METERS, this does not exist either currently. 
    
    # Link level
    LINK_TRAVEL_MINUTES, LINK_TRAVEL_METERS, LINK_DISTANCE_METERS, 
    
    # Coop level 
    starts_with("COOP_FARMERS"), 
    COOP_N_KNOWN_BS, 
    # starts_with("COOP_DISTRICT_"), -COOP_DISTRICT_NAME,
    starts_with("COOP_STATUS_"), 
    COOP_BS_10KM_TRI,
    
    # More endogenous: 
    COOP_N_KNOWN_BUYERS, 
    COOP_RFA, COOP_UTZ, COOP_FT,
    COOP_CERTIFIED 
    # Never include those, because our observed links data is biased towards link existence when there is a SSI (the CCP, Cargill's SSI). 
    # Don't include dummies for other SSIs than Cargill's, because having many training data from Cargill means our observed links data is biased towards link existence when there is no other SSI than Cargill's. 
    # COOP_HAS_SSI, 
    # starts_with("COOP_SSI_"), 
   
  ) %>%
  names()  
  
# Restricted list of more exogenous features regarding the further applications of the model. 
# This additionally exclude certification related variables, as well as the number of known buyers. 
stg2_exofeatures = 
  stg2_allfeatures %>% 
  grep(~., pattern = "DISTANCE|TRAVEL|N_BS_WITHIN|N_KNOWN_BS|N_COOP_IN|LICBUY|STATUS|_TRI|SETTLEMENT|COOP_FARMERS$", 
       value = TRUE) %>% 
  unique()

setdiff(stg2_allfeatures, stg2_exofeatures)

stg2_formula_allfeatures = as.formula(paste0("LINK_IS_ACTUAL_COOP_class ~ ", paste0(stg2_allfeatures, collapse = " + ")))
stg2_mformula_exofeatures = as.formula(paste0("LINK_IS_ACTUAL_COOP_class ~ ", paste0(stg2_exofeatures, collapse = " + ")))



```

### Simple fit
```{r}
set.seed(8888)

stg2_simple =
  boost_tree(
    mode = "classification",
    mtry = 6,
    trees = 5,
    min_n = 5
  ) %>%
  fit(data = stg2_development,
      formula = stg2_formula_allfeatures)

stg2_simple

```


### caret
```{r}
# Custom summary function (otherwise not possible to obtain all metrics in a single run of caret::train)
customSummary <- function(data, lev = NULL, model = NULL) {
  # Calculate twoClassSummary metrics
  twoClass <- twoClassSummary(data, lev, model)
  
  # Calculate prSummary metrics
  pr <- prSummary(data, lev, model)
  
  # Combine the results
  out <- c(twoClass, pr)
  
  # Add accuracy
  accuracy <- sum(data$obs == data$pred) / length(data$obs)
  out <- c(out, Accuracy = accuracy)
  
  return(out)
}

set.seed(8888)
seeds <- vector(mode = "list", length = 6)
for(i in 1:6) seeds[[i]] <- sample.int(1000, 36)
seeds[[6]] = sample.int(1000, 1)

model2_caret_xgb = 
  train(
    x = stg2_development %>% select(all_of(stg2_allfeatures)),
    y = stg2_development$LINK_IS_ACTUAL_COOP_class, 
    method="xgbTree", 
    metric = "ROC",
    tuneLength=3,
    # More about this function here: https://topepo.github.io/caret/model-training-and-tuning.html#control
    trControl=trainControl(method="cv",number=5,
                           savePredictions=T, # TRUE is equivalent to "all" and is necessary to use thresholder() later on. 
                           #returnResamp = TRUE,
                           verboseIter = TRUE,
                           summaryFunction = customSummary, 
                           classProbs = TRUE,  # necessary to obtain ROC
                           seeds = seeds
                           ) 
  )

model2_caret_xgb

saveRDS(model2_caret_xgb, 
        here("temp_data", "model", "caret", "stage_2", "model2_caret_xgb"))
```


### familiar
```{r}
stop()
# Columns with NAs
names(which(colSums(is.na(stg2_development)) > 0)) %>% intersect(stg2_allfeatures)


# Experimental design 
exp_design = "cv(fs+mb, 5)"  # "bt(fs+mb,5)"

# Repository for familiar 1st stage 
# summon_familiar writes all it does in a repo. It returns nothing here.  
stage2_expdes_repo = here("temp_data", "model", "familiar", "stage_2", gsub(",","_",exp_design))
dir.create(stage2_expdes_repo)

# let's go
summon_familiar(
  
  formula = stg2_formula_allfeatures,
  data = stg2_development %>% select(LINK_ID, LINK_IS_ACTUAL_COOP_class, all_of(stg2_allfeatures)),
  experiment_dir = stage2_expdes_repo,
  sample_id_column = "LINK_ID",
  outcome_name = "Link existence",
  outcome_column = "LINK_IS_ACTUAL_COOP_class",
  outcome_type = "binomial",
  experimental_design = exp_design, #"fs + mb", #  # "cv(bt(fs,100) + mb, 3)",

  # Use bt because we have many features compared to the number of observations.  "The most practical application of bt is for repeating feature selection multiple times (e.g. bt(fs,50)+mb+ev), as this allows for aggregating variable importance and reducing the effect of random selection."

  learner = "xgboost_tree",
  
  # Set hyper-parameters so that feature selection and model building stages do not tune this. 
  # Otherwise, training the model is too long! 
  # However, do NOT specify the signature size (i.e. the number of features to include "sign_size"), to let this be optimized based on feature importance. 
                                            
  # input default values in ranger
  fs_method_parameter = list("random_forest_ranger_permutation"=
                               list("n_tree" = 500,
                                     "sample_size" = 0.632,
                                     "m_try" = 0.5, # ranger's default is round(sqrt(length(stg2_allfeatures)),0),
                                      # but apparently familiar uses a share 
                                     "node_size" = 10,
                                     "tree_depth" = 10 # ranger's default is 0 which means infinite. Here Inf is not accepted, so put the higher bound of familiar's default range. 
                                     )),
  # Input default values in xgboost::xgb.train 
  # hyperparameter = list("xgboost_tree"=
  #                         list("n_boost" = 2.7, # this means 500 trees
  #                              "learning_rate" = -1.5, # for log10 to make ~0.3, the default (eta)
  #                              "alpha" = -6, # for log10 to make 0, the default
  #                              "lambda" = 0, # for log10 to make 1, the default
  #                              "tree_depth" = 6,
  #                              "sample_size" = 0.632,
  #                              "min_child_weight" = 0.3, # for log10 -1 to make 1, the default
  #                              "gamma" = -1 # no default in xgboost, just the middle of familiar's default range
  #                              
  #                               )),
  
  # imbalance_correction_method = "random_undersampling", # do not specify, to avoid any kind of under-sampling, since we did it in external pre-processing.  
  parallel = TRUE,
  parallel_nr_cores = detectCores() - 1, 
  
  # PRE-PROCESSING ARGS
  # (not all "none" are the defaults)
  filter_method = "none", # no feature to be filtered in pre-processing
  transformation_method = "none", 
  normalisation_method = "none",
  cluster_method = "hclust", # the default. This is categorised in data processing, but it will affect feature selection. 
  # imputation_method does not matter bc we have no NA. 
  
  # FEATURE SELECTION & OPTIMIZATION 
  fs_method = "random_forest_ranger_permutation", # see https://cran.r-project.org/web/packages/familiar/vignettes/feature_selection_precompiled.html

  # vimp_aggregation_method = "borda", # borda is the default. Check guidance to depart. 
  
  # hyperparameter = list("ranger" = list()), #  "If no parameters are provided, sequential model-based optimisation is used to determine optimal hyperparameters."
  
  # EVALUATION INFERENCE
  # The default is "bootstrap_confidence_interval" or "bci", so we have to tell the model to do just quick point estimates where we don't care much about inference. Especially as bci can easily be queried in post-processing.  
  skip_evaluation_elements = c("feature_expressions", "feature_similarity", 
                               "fs_vimp",  "hyperparameters", "ice_data", 
                                "univariate_analysis"), #"model_vimp", "permutation_vimp", 
  
  # part of this list elements are useless now, since they are skipped by the above. 
  estimation_type = list("prediction_data" = "bci", 
                         "model_performance"="bci", 
                         "permutation_vimp" = "point", 
                         "ice_data"= "point", 
                         "auc_data" = "point", 
                         "decision_curve_analyis" = "point"), 
  # estimation_type = list("prediction_data" = "hybrid", "model_performance"="hybrid", 
  #                        "permutation_vimp" = "ensemble", 
  #                        "ice_data"= "ensemble", 
  #                        "auc_data" = "ensemble", 
  #                        "decision_curve_analyis" = "ensemble"), 
  confidence_level = 0.95, # the default. 
  detail_level = "hybrid" # the default. See evaluation vignette. 
)

```

### Finders
This block produces convenient finder objects to access familiar outputs. 
```{r}
## ID TO SELECT MODEL TO WORK WITH IN ALL OF BELOW SCRIPT
# ---------------------------------------------
model2_date = "20241206091347"
# ---------------------------------------------

# Finders of familiar outputs

# Feature info - this gives generic info about the features in the model 
# feature_info = readRDS(here(stage2_expdes_repo, "20241127134237_feature_info.RDS"))

# Iterations - this gives info about the structure of the sampling applied by the experimental design. 
# iterations = readRDS(here(stage2_expdes_repo, "20241125194101_iterations.RDS"))

# familiar_data - a maxi list containing all info of a run. 
# famdat = readRDS(here(stage2_expdes_repo, "familiar_data", "20241128122859_random_forest_ranger_random_forest_ranger_permutation_1_1_ensemble_1_1_development_data.RDS"))

# Model development results - to report model performance
stage2_results = here(stage2_expdes_repo, "results", "pooled_data")

# Models - to run predictions
stage2_model_path = here(stage2_expdes_repo, 
                         "trained_models", 
                         "xgboost_tree", 
                         "random_forest_ranger_permutation")

# Select the model/ensemble we want to work with 

stage2_ensemble_names = list.files(stage2_model_path, pattern = "ensemble")
model2_name = 
  stage2_ensemble_names %>% 
  grep(~.,  
       pattern = model2_date, 
       value = TRUE) # take the first one in case there are several
                                          
model2 = readRDS(here(stage2_model_path, model2_name))
model2

```

# READ MODELS
## 1st stage
This block produces convenient finder objects to access familiar outputs. 
```{r}
# All 1st stage models have been written by familiar in 
stage1_expdes_repo

# We use one specifically, identified by: 
# ---------------------------------------------
model_date = "20241204190335"
# ---------------------------------------------

# Finders of familiar outputs

# Feature info - this gives generic info about the features in the model 
# feature_info = readRDS(here(stage1_expdes_repo, "20241127134237_feature_info.RDS"))

# Iterations - this gives info about the structure of the sampling applied by the experimental design. 
# iterations = readRDS(here(stage1_expdes_repo, "20241125194101_iterations.RDS"))

# familiar_data - a maxi list containing all info of a run. 
# famdat = readRDS(here(stage1_expdes_repo, "familiar_data", "20241128122859_random_forest_ranger_random_forest_ranger_permutation_1_1_ensemble_1_1_development_data.RDS"))

# Model development results - to report model performance
stage1_results = here(stage1_expdes_repo, "results", "pooled_data")

# Models - to run predictions
stage1_model_path = here(stage1_expdes_repo, 
                         "trained_models", 
                         "random_forest_ranger", 
                         "random_forest_ranger_permutation")

# Select the model/ensemble we want to work with 

stage1_ensemble_names = list.files(stage1_model_path, pattern = "ensemble")
model1_name = 
  stage1_ensemble_names %>% 
  grep(~.,  
       pattern = model_date, 
       value = TRUE) # take the first one in case there are several
                                          
model1 = readRDS(here(stage1_model_path, model1_name))
model1

```

## 2nd stage 
```{r}
model2_caret_xgb = readRDS(here("temp_data", "model", "caret", "stage_2", "model2_caret_xgb"))

```


# PERFORMANCE

## 1st stage 

```{r}
# Performance metrics are stored here
perf_metrics = read.csv2(here(stage1_results, "performance", "performance_metric.csv"))

perf_metrics

# Normalement ces plots sont déjà exportés automatiquement par summon_familiar, mais apparemment pas pour toutes les métriques. 
# This takes ~10min with a 200-models ensemble
plot_perf_model1 = 
  familiar::plot_model_performance(
  object = model1,
  draw = TRUE,
  facet_by = "metric",
  data = stg1_development %>% select(CELL_ID, CELL_PROP_VOLUME_COOPS, all_of(stg1_allfeatures)),
  estimation_type = "bci",
  metric = c("mse", "rse", "r2_score")) #"rmse",  "explained_variance", 

# Save plot
plot_perf_model1
ggsave(
  filename = paste0("performance_metrics.png"),
  path = here("outputs", "familiar", "stage_1", model1_date))

```

## 2nd stage
```{r}
# Access resampling results
resamples <- model2_caret_xgb$resample

# Calculate mean and standard deviation of performance metrics
mean_roc <- mean(resamples$ROC)
sd_roc <- sd(resamples$ROC)
mean_sens <- mean(resamples$Sens)
sd_sens <- sd(resamples$Sens)
mean_spec <- mean(resamples$Spec)
sd_spec <- sd(resamples$Spec)

# This is to access performance metrics aggregated over resamples for different models 
resamps <- resamples(list(first_caret = model2_caret_xgb, first_caret2 = model2_caret_rf))
summary(resamps)

# And to run statistical tests of the diff in performance between models: 
# https://topepo.github.io/caret/model-training-and-tuning.html#extracting-predictions-and-class-probabilities


```

# EXPLANATION

Importance ranks features wrt. each other but cannot tell direction or magnitude. 
Explanation is produced by feature, and can be interpreted in target scale. 

### 1st stage 

#### Descriptive stats 
Features in the development set 
```{r}
# Report separately for most exogenous features and more endogenous ones 
stg1_development_exo_features =
  stg1_development %>% 
  select(Sample = SPLIT, 
         `Coop outlet share` = CELL_PROP_VOLUME_COOPS, 
         `Cocoa output from cell (kg)` = CELL_VOLUME_KG,
         
         `Shortest Eucl. distance to a coop (m)` = CELL_MIN_DISTANCE_METERS, 
         `Shortest road distance to a coop (m)` = CELL_MIN_TRAVEL_METERS, 
         `Avg. Eucl. distance of the 5 nearest coops (m)` = CELL_AVG_DISTANCE_METERS_5_NEAREST_COOPS, 
         `Avg. road distance of the 5 nearest coops (m)` = CELL_AVG_TRAVEL_METERS_5_NEAREST_COOPS, 
         
         `# buying stations within 72km` = CELL_N_BS_WITHIN_DIST, 
         `# coops in department` = CELL_N_COOP_IN_DPT,
         `# registered licensed buyers in department` = CELL_AVG_N_LICBUY_IN_DPT, 

         `Settlements area (ha)` = CELL_SETTLEMENT_HA,
         `Terrain ruggedness (TRI, mm)` = CELL_TRI_MM,
         
         `Nearest coop being SCOOPS` = CELL_PROP_1_NEAREST_COOP_STATUS_SCOOPS,
         `Proportion of 5 nearest coops being SCOOPS` = CELL_PROP_5_NEAREST_COOP_STATUS_SCOOPS,
         `Proportion of all coops within 72 km being SCOOPS` = CELL_PROP_COOP_STATUS_SCOOPS,
         
         `Nearest coop being COOP-CA` = CELL_PROP_1_NEAREST_COOP_STATUS_COOPCA,
         `Proportion of 5 nearest coops being COOP-CA` = `CELL_PROP_5_NEAREST_COOP_STATUS_COOPCA`,
         `Proportion of all coops within 72 km being COOP-CA` = CELL_PROP_COOP_STATUS_COOPCA,
         
         `Total # farmers of 5 nearest coops` = CELL_COUNT_5_NEAREST_COOP_FARMERS,
         `Total # BS of 5 nearest coops` = CELL_COUNT_5_NEAREST_COOP_N_KNOWN_BS,
         `Avg. TRI around 5 nearest coops (mm)` = CELL_AVG_5_NEAREST_COOP_BS_10KM_TRI,

         `Avg. settlements extent around 5 nearest coops` = CELL_AVG_5_NEAREST_COOP_BS_10KM_SETTLEMENT_HA
         ) 

datasummary_skim(data = stg1_development_exo_features,
                output = here("outputs", "input_data_descriptives", paste0("cells_stg1dev_",MODEL_RESOLUTION_KM,"km_exo_features.png")))


# For more endogeneous features


```


#### Feature importance
```{r}
importance_repo = here(stage1_results, "variable_importance")

permut_vimp = read.csv2(here(importance_repo, "variable_importance_permutation.csv"))

vimp_top10 = 
  permut_vimp %>% 
  filter(similarity_threshold == 1 & data_set == "development" & value !=0) %>% 
  arrange(desc(value)) %>% 
  pull(feature) %>% 
  head(10)

# The plot_model_signature_occurrence method plots the occurrence of features among the first 5 ranks across an ensemble of models (if available). The rank threshold can be specified using the rank_threshold argument or the eval_aggregation_rank_threshold parameter (summon_familiar).


#Note: -------
# The summon_familiar outputs below are not yet aggregated, they are bootstrap-specific lists of ranked features used in model development.  
# stage1_vimp = here(stage1_expdes_repo, "variable_importance")
# vimp = readRDS(here(stage1_vimp, "20241127134237_fs_random_forest_ranger_permutation.RDS"))
# vimp_hp = readRDS(here(stage1_vimp, "random_forest_ranger", "20241127134237_hyperparameters_random_forest_ranger_1_1.RDS"))
```

#### Explanation
Here we use Individual Conditional Expectation (ICE) and Partial Dependence (PD) plots.
All this is sketchy, and interpretations are challenging !!! 

```{r}
# These plots are readily available in the repository below. 
explanation_repo = here(stage1_results, "explanation")

# To have a global picture, look at the correlation tests (I am not sure about this!)

pd_corr_table = data.frame()
for(impvar in vimp_top10){
  pdvar = 
    read.csv2(here(explanation_repo, paste0("explanation_pd_", impvar, ".csv"))) %>% 
    filter(data_set == "development") 
  
  cortest_pd = 
    stats::cor.test(x = as.numeric(pdvar$feature_x_value),
                    y = as.numeric(pdvar$predicted_outcome))

  cortest_actual = 
    stats::cor.test(x = stg1_development %>% pull(impvar),
                    y = stg1_development$CELL_PROP_VOLUME_COOPS)

  pd_corr_table[1:2,impvar] = c(cortest_pd$estimate, cortest_pd$p.value)
  
  pd_corr_table[3:4,impvar] = c(cortest_actual$estimate, cortest_actual$p.value)
  row.names(pd_corr_table) = c("Correlation coefficient PD", "p value PD",
                               "Correlation coefficient", "p value")
}

pd_corr_table
```



### 2nd stage 
Feature importance
```{r}
varImp(model2_caret_xgb)

model2_caret_xgb$finalModel$importance


model2_caret_xgb$finalModel$importance %>% as.data.frame() %>% arrange(desc(`%IncMSE`))



```

Explanation
```{r}

```


# PREDICTION
Here, we build the prediction setS for each stage. 
Based on AoA of 1st stage model. 
Moreover, we report here on the Novelty of cells and links in (and out of) the prediction sets. 

## Read developed models
```{r}
model2_caret_xgb = readRDS(here("temp_data", "model", "caret", "stage_2", "model2_caret_xgb"))

```


## AoA
```{r}
# Requires the model to be trained with caret, with cross-validation and not bootstraps

model1_caret_cv = 
  train(
    x = stg1_development %>% select(all_of(model1@required_features)),
    y = stg1_development$CELL_PROP_VOLUME_COOPS, 
    method="rf", 
    importance=TRUE, 
    tuneLength=1,
    trControl=trainControl(method="cv",number=5,savePredictions=T)
  )

model1_caret_cv$results

aoa1 = 
  aoa(newdata = cells %>% select(all_of(model1@required_features)),
      model = model1_caret_cv)

cells$CELL_IS_IN_AOA = if_else(aoa1$AOA == 1, TRUE, FALSE)

cells$CELL_IS_IN_AOA %>% summary()

# note that it discards some Cargill links (~330)
```

### Map 
Map here the AoA together with all cell information statuses.  
```{r}
datasummary_crosstab(data = cells, CELL_IS_IN_AOA ~ CELL_NO_ACTUAL_LINK_DATA)
datasummary_crosstab(data = cells, CELL_IS_IN_AOA ~ CELL_2ND_STAGE_ONLY)
datasummary_crosstab(data = cells, CELL_IS_IN_AOA ~ CELL_VOLUME_OBSERVED)

toplot = 
  cells %>% 
  st_as_sf(coords = c("CELL_LONGITUDE", "CELL_LATITUDE"), crs = 4326) %>% 
  st_transform(civ_crs) %>% 
    mutate(
      `Cell information content` = case_when(
        # order matters, AoA condition shoudl be first to overwrite "To predict" or "Data for..." statuses for instance (case_when gives value corresponding to the first match)
        !CELL_IS_IN_AOA ~ "Outside AoA of 1st stage", 
        CELL_NO_POTENTIAL_LINK ~ "No cooperative within 72 km", 
        CELL_NO_ACTUAL_LINK_DATA ~ "To predict",
        CELL_VOLUME_OBSERVED ~ "Data for both stages",
        CELL_2ND_STAGE_ONLY ~ "Data for 2nd stage only",
        ), 
      `Cell information content` = factor(`Cell information content`,
                                          levels = c("Data for both stages",
                                                     "Data for 2nd stage only", 
                                                     "To predict", 
                                                     "Outside AoA of 1st stage", 
                                                     "No cooperative within 72 km"))
) 

toplot$`Cell information content` %>% table()    

cell_info_map = 
  ggplot(toplot) +
    geom_sf(aes(col = `Cell information content`, fill = `Cell information content`), size = 0.3, shape = 22) + #, shape = 15
    scale_colour_manual(
      values = c("Data for both stages" = "purple",
                 "Data for 2nd stage only" = "blue", 
                 "To predict" = "yellow", 
                 "Outside AoA of 1st stage" = "darkgrey",
                 "No cooperative within 72 km" = "lightgrey")
    ) +
    scale_fill_manual(
      values = c("Data for both stages" = "purple",
                 "Data for 2nd stage only" = "blue", 
                 "To predict" = "yellow", 
                 "Outside AoA of 1st stage" = "darkgrey",
                 "No cooperative within 72 km" = "lightgrey")
    ) +
    geom_sf(data = departements, fill = "transparent", col = "black") +
    theme_bw() + 
    # theme(legend.key.size = unit(3, "cm")) + 
    guides(colour = guide_legend(override.aes = list(size=10))) +
    scale_x_continuous(breaks = xlabs, labels = paste0(xlabs,'°W')) +
    scale_y_continuous(breaks = ylabs, labels = paste0(ylabs,'°N'))
  
cell_info_map

ggsave(  
  plot = cell_info_map, 
  filename = "map_cell_info.png",
  path = here("outputs", "input_data_descriptives"), 
  width = 25, 
  height = 20,
  units = "cm")

# ggplot(toplot) +
#     geom_sf(aes(col = CELL_IS_IN_AOA), size = 1) + #, shape = 15
#     geom_sf(data = departements, fill = "transparent", col = "black")

```


## Novelty
### caret
The caret package does not have built-in functionality specifically for computing the "novelty" of samples in the same way the familiar package does. 
One alternative approach proposed by Copilot is to use distance-based methods or leverage the Mahalanobis distance to measure how far new samples are from the training data distribution.
```{r}
# Calculate Mahalanobis distance for test data
cov_matrix <- cov(stg2_development %>% select(all_of(stg2_allfeatures)))
center <- colMeans(stg2_development %>% select(all_of(stg2_allfeatures)))
links$LINK_mahalanobis_dist <- mahalanobis(links %>% select(all_of(stg2_allfeatures)), center, cov_matrix)

```

### familiar
```{r}
# Novelty in development data 
devdat_prediction_1 = read.csv2(here(stage1_results, "prediction", "prediction.csv"))
devdat_prediction_2 = read.csv2(here(stage2_results, "prediction", "prediction.csv"))

devdat_prediction_1$novelty %>% as.numeric() %>% summary()

# It is possible to add features that were not in the model initial formula, to gauge novelty (?)
# but would it make sense (to include LU vars) here? 

# Novelty in to-predict data

cells$CELL_NOVELTY = predict(object = model1, newdata = cells, type = "novelty")

cells$CELL_NOVELTY %>% summary()

# Novelty in the Cells data is in the range of novelty in the 1st stage dev data. 
# So we don't take it further into account. 
```



## Prediction sets
```{r}
# Keep cells that are sufficiently close in terms of AoA, and, 
#to reduce computation, that have no close (72km) coop, as for those we attribute null probas.  
cells_topredict = 
  cells %>% 
  filter(CELL_IS_IN_AOA & !CELL_NO_POTENTIAL_LINK)

links = 
  links %>%
  left_join(cells %>% select(CELL_ID, CELL_IS_IN_AOA), 
            by = "CELL_ID")


# Should it be the under-sampled data rather here? NO, I don't think so. We DO want to make predictions for all virtual links! 
links_topredict =
  links %>% 
  filter(CELL_IS_IN_AOA & !CELL_NO_POTENTIAL_LINK)


```

## Development/prediction balance tests
 
```{r}

```


## Predict 1st stage
```{r}
tic()
cells_topredict$CELL_SHARE_COOP = predict(model1, newdata = cells_topredict)$predicted_outcome
toc()
# From here, to shorten code, let's start a fresh naming convention for the target feature LINK_PROBA. 

cells_topredict$CELL_SHARE_COOP %>% summary()

cells = 
  cells %>% 
  left_join(cells_topredict %>% select(CELL_ID, CELL_SHARE_COOP), 
            by = "CELL_ID")

```

### Threshold
1st stage threshold: whether the share of coop outlet is significantly different from zero (one-sided t-test) 
```{r}
# In each cell, conduct a one-sided t-test that the predicted share of coop outlet is positive. 

# Shall produce variable CELL_SHARE_COOP_SIGNI which is the same as CELL_SHARE_COOP, but 0 where not significantly different from zero. 

cells =
  cells %>% 
  mutate(CELL_SHARE_COOP_SIGNI = if_else(CELL_SHARE_COOP < 0.1,  
                                         0, 
                                         CELL_SHARE_COOP))

cells$CELL_SHARE_COOP %>% summary()
cells$CELL_SHARE_COOP_SIGNI %>% summary()

```

### Determinist prediction
This is just where we are sure that cocoa can be sold to a cooperative because there is no coop. 
```{r}
cells =
  cells %>% 
  mutate(CELL_SHARE_COOP_SIGNI = if_else(CELL_NO_POTENTIAL_LINK, 
                                          0, 
                                          CELL_SHARE_COOP_SIGNI))

cells$CELL_SHARE_COOP_SIGNI %>% summary()

stopifnot(sum(is.na(cells$CELL_SHARE_COOP_SIGNI)) == sum(aoa1$AOA==0))
```


## Predict 2nd stage
```{r}
# Predict the existence that a link exists
tic()
links_topredict$LINK_PROBA = predict(model2_caret_xgb, 
                                     newdata = links_topredict %>% select(all_of(model2_caret_xgb$finalModel$feature_names)), 
                                     type = "prob")$Actual_links
toc()

# From here, to shorten code, let's start a fresh naming convention for the target feature LINK_PROBA. 

links_topredict$LINK_PROBA %>% summary()

links = 
  links %>% 
  left_join(links_topredict %>% select(LINK_ID, LINK_PROBA), 
            by = "LINK_ID")

```


### Threshold
2nd stage threshold: whether the (still conditional and not normalised) proba that there is a link is higher than the threshold that minimises false positives. 
```{r}
# Identify the optimal class probability threshold, and apply it to every link

# To be conservative regarding the extent of supply sheds, we have a preference for false negatives with regards to false positives. Thus, we choose a threshold that maximises the performance metric about false positives: we minimise the   
optimal_thresholds = thresholder(model2_caret_xgb, threshold = seq(0, 1, by = 0.05))
# seq(0.0001, 0.001, by = 0.0001)

(thresh = 
  optimal_thresholds %>% 
  arrange(desc(Precision)) %>% 
  head(1) %>% 
  pull(prob_threshold))

links = 
  links %>% 
  mutate(LINK_PROBA_THRESH = if_else(LINK_PROBA < thresh, 
                                     0, 
                                     LINK_PROBA)) # returns NA for NA probas (!AoA)
```


### Determinist prediction
This is just where we are sure that no link can exist because there is no coop. 
```{r}
links =
  links %>% 
  mutate(LINK_PROBA_THRESH = if_else(CELL_NO_POTENTIAL_LINK, 
                              0, 
                              LINK_PROBA_THRESH)) # it could also be 1 here, since we normalise then. But keep some variation between links with a positive proba. 

# After this, the number of links that are NA is 297074
links$LINK_PROBA_THRESH %>% summary()
# which is the same as the number of links in cells outside the AoA. 
n_links_outside_aoa = nrow(filter(links, !CELL_IS_IN_AOA)) 

stopifnot(
  links %>% filter(is.na(LINK_PROBA_THRESH)) %>% nrow() ==  n_links_outside_aoa
)


links$LINK_PROBA %>% quantile(seq(0.99, 1, 0.001), na.rm = T)
links$LINK_PROBA_THRESH %>% quantile(seq(0.999, 1, 0.0001), na.rm = T)

```





# POST-PROCESSING 

## Unconditional probabilities
Here we multiply probabilities predicted in each stage by each other and/or by the share of cocoa presence. 
This is all at the Links level. 
There are several combinations, yielding different interpretations: 

```{r}
links_beforepost = links

links = 
  links %>% 
  left_join(
    cells %>% select(CELL_SHARE_COOP_SIGNI, CELL_ID), # CELL_SHARE_COOP, not even sure it is necessary to join this. 
    by = "CELL_ID"
  ) 

links = 
  links %>% 
  mutate(
    LINK_UNCOND_PROBA = CELL_SHARE_COOP_SIGNI * LINK_PROBA, # include this just for exploration. 
    LINK_UNCOND_PROBA_THRESH = CELL_SHARE_COOP_SIGNI * LINK_PROBA_THRESH
  )

```



## Normalisation (cell perspective)
We do it after unconditioning, to normalise unconditional probabilities too. 
```{r}
    # Work non-thresholded proba for now, but we will surely not keep them. 

links = 
  links %>% 
  group_by(CELL_ID) %>% 
  mutate(
    CELL_NORMSUM_THRESH = sum(LINK_PROBA_THRESH), 
    CELL_UNCOND_NORMSUM_THRESH = sum(LINK_UNCOND_PROBA_THRESH)
  ) %>% 
  ungroup() %>% 
  mutate(
    # When denominator is null, i.e. all links in cell have probas = 0, then make the normalised probas = 0.
    # When it's NA, it means we are in a cell outside the AoA, so leave it NA
    LINK_PROBA_THRESH_NORMED = case_when(
      CELL_NORMSUM_THRESH > 0 ~ LINK_PROBA_THRESH / CELL_NORMSUM_THRESH, 
      is.na(CELL_NORMSUM_THRESH) ~ NA,
      TRUE ~ 0
      ), 
    LINK_UNCOND_PROBA_THRESH_NORMED = case_when(
      CELL_UNCOND_NORMSUM_THRESH > 0 ~ LINK_UNCOND_PROBA_THRESH / CELL_UNCOND_NORMSUM_THRESH, 
      is.na(CELL_UNCOND_NORMSUM_THRESH) ~ NA,
      TRUE ~ 0
      )
  )

stopifnot(
links %>% filter(is.na(LINK_PROBA_THRESH_NORMED)) %>% pull(CELL_IS_IN_AOA) %>% any() == FALSE
)

links %>% filter(is.na(LINK_PROBA_THRESH_NORMED)) %>% nrow() 
links %>% filter(is.na(LINK_UNCOND_PROBA_THRESH_NORMED)) %>% nrow() 

summary(links$CELL_NORMSUM_THRESH)
summary(links$CELL_UNCOND_NORMSUM_THRESH)
# It is not anormal that these sums are higher than 1, that's precisely why we normalise actually. 

# links %>% filter(CELL_NORMSUM_THRESH > 1) %>% View()


stopifnot(
  links$LINK_PROBA_THRESH_NORMED %>% sum(na.rm = T) %>% round(5) + 
    length(unique(pull(filter(links, CELL_NORMSUM_THRESH == 0), CELL_ID))) == 
    length(unique(links_topredict$CELL_ID)) |
    
  links$LINK_UNCOND_PROBA_THRESH_NORMED %>% sum(na.rm = T) %>% round(5) + 
    length(unique(pull(filter(links, CELL_UNCOND_NORMSUM_THRESH == 0), CELL_ID))) == 
    length(unique(links_topredict$CELL_ID)) 
)

```




## Links most likely
This is an important step, where we define, for every cell, to which coop it most likely supplies (conditional on supplying any coop in the first place). 

This is not yet non-overlapping polygons though, as we still have many equi-probabilities... 

```{r}
# Find the max conditional, normalised proba in every cell. 
# Using the unconditional probas would yield exactly the same result, as it just differs by a cell-level quantity, 
# EXCEPT in cells that don't pass the 1st stage threshold. There, unconditional probas would all be null, but conditional probas aren't. So using conditional probas allows to also determine which coop is most likely supplied in cells not selling to coops at all. 

links = 
  links %>% 
  group_by(CELL_ID) %>% 
  mutate(
    LINK_PROBA_THRESH_NORMED_CELLMAX = max(LINK_PROBA_THRESH_NORMED), 
  ) %>% 
  ungroup() %>% 
  mutate(LINK_IS_MOST_LIKELY = case_when(
    LINK_PROBA_THRESH_NORMED_CELLMAX == 0 | # where all probas are null
      # or where their maximum is strictly higher than the link's proba, the link is not most likely
    LINK_PROBA_THRESH_NORMED_CELLMAX > LINK_PROBA_THRESH_NORMED ~ FALSE, 
    is.na(LINK_PROBA_THRESH_NORMED_CELLMAX) ~ NA,
    TRUE ~ TRUE
    )
  ) %>% 
  group_by(CELL_ID) %>% 
  mutate(CELL_N_MOST_LIKELY_LINKS = sum(LINK_IS_MOST_LIKELY, na.rm = T)) %>% 
  ungroup() 

# Equi-probabilities are allowed. We have them for many of the observed links, which 
# predicted probability to exist is 1, and thus normalised probability is 1/n with n is the number of observed links in cell. 
# Plus a few truly predicted probas. 
links %>%   
  filter(CELL_N_MOST_LIKELY_LINKS > 1) %>% 
  arrange(CELL_ID) %>% 
  View()
  
links %>%   
  filter(CELL_N_MOST_LIKELY_LINKS > 1) %>% 
  filter(!is.na(PRO_ID)) %>% 
  nrow()

```





## Normalisation (coop perspective)
We normalise, from the perspective of every coop, for six types of supply sheds, i.e. the combinations of 
either conditional or unconditional probabilities to be linked with the coop, for three kinds of cells: productive only, prospective only, and either. 
```{r}
# The idea is to export coop-level data sets with sourcing shed shapes, one object for each type, and each time the weighted cocoa area in all sourcing sheds


```



# EXPORT 
```{r}
saveRDS(cells, 
        here("temp_data", "model", "cells.Rdata"))

saveRDS(links, 
        here("temp_data", "model", "links.Rdata"))
```
































# DEPRECATED CODE   


## Hold-out validation 
```{r}

(test_pred_prob <- predict(stg2_mfit, 
                             new_data=stg2_test, 
                             type = "prob"))

stg2_test$LINK_PRED_ACTUAL_COOP_prob = test_pred_prob$`.pred_Actual_links`


(test_pred_class <- predict(stg2_mfit, 
                             new_data=stg2_test, 
                             type = "class")) # this implements a 50% threshold, 
# i.e., if the predicted link is more likely to exist than to not exist, the prediction is classified as "Actual link" 
stg2_test$LINK_PRED_ACTUAL_COOP_class = test_pred_class$.pred_class

stg2_test = 
  stg2_test %>% 
  mutate(TP = LINK_PRED_ACTUAL_COOP_class == "Actual_links"  & LINK_IS_ACTUAL_COOP_class == "Actual_links",
         TN = LINK_PRED_ACTUAL_COOP_class == "Virtual_links" & LINK_IS_ACTUAL_COOP_class == "Virtual_links",
         FP = LINK_PRED_ACTUAL_COOP_class == "Actual_links"  & LINK_IS_ACTUAL_COOP_class == "Virtual_links",
         FN = LINK_PRED_ACTUAL_COOP_class == "Virtual_links" & LINK_IS_ACTUAL_COOP_class == "Actual_links")

```


### Accuracy 
we can calculate the overall accuracy score as a sum of instances where predicted and actual classes match divided by the total number of rows:
```{r}

(accuracy = sum(stg2_test$LINK_PRED_ACTUAL_COOP_class == stg2_test$LINK_IS_ACTUAL_COOP_class) / nrow(stg2_test))
(accuracy = (sum(stg2_test$TP) + sum(stg2_test$TN) ) / (sum(stg2_test$TP) + sum(stg2_test$TN)  + sum(stg2_test$FP) + sum(stg2_test$FN)))

```

### True Positive Rate (Recall) 
```{r}
(recall = sum(stg2_test$TP) / (sum(stg2_test$TP) + sum(stg2_test$FN)))
```

### False Negative Rate (probability of false alarm)
```{r}
(fpr = sum(stg2_test$FP) / (sum(stg2_test$TN) + sum(stg2_test$FP)))
```

### Precision
```{r}
(precision = sum(stg2_test$TP) / (sum(stg2_test$TP) + sum(stg2_test$FP)))

```


### Confusion Matrix  
```{r}
# This requires package caret which fails to install. 
# cm = confusionMatrix(stg2_test$LINK_IS_ACTUAL_COOP_class, stg2_test$LINK_PRED_ACTUAL_COOP_class)
# 
# 
# # Plot it 
# cfm <- as_tibble(cm$table)
# plot_confusion_matrix(cfm, target_col = "Reference", prediction_col = "Prediction", counts_col = "n")

```

### PR-AUC
```{r}
prc_xgboost_test = 
  pr_curve(
    data = stg2_test, 
    truth = LINK_IS_ACTUAL_COOP_class,
    LINK_PRED_ACTUAL_COOP_prob, 
    event_level = "second"
)

(PRAUC = 
  pr_auc(
    data = stg2_test, 
    truth = LINK_IS_ACTUAL_COOP_class,
    LINK_PRED_ACTUAL_COOP_prob, 
    event_level = "second",
    estimator = "binary"
))

ggplot(prc_xgboost_test, aes(x = recall, y = precision)) +
  geom_path() +
  coord_equal() +
  theme_bw()  
  # legend(legend = c(paste0("Main model \nAUC = ",round(PRAUC, 2))))
  
```

### AUROC
```{r}
roc_xgboost_test = 
  roc(
  data = stg2_test, 
  response = LINK_IS_ACTUAL_COOP_class,
  predictor = LINK_PRED_ACTUAL_COOP_prob,
  quiet = TRUE
)

(AUC = roc_xgboost_test$auc)

plot(pROC::smooth(roc_xgboost_test), col = "blue", lwd = 1) 
legend(
  "bottomright",
  col = "blue",
  lwd = 1,
  legend = c(paste0("Main model \nAUC = ",round(AUC, 2)))
)
```


## Prediction (deprecated)
## Simple predict (deprecated)
```{r}
stg1_predict = 
  cells %>% 
  filter(!CELL_NO_POTENTIAL_LINK)


stg1_predict$CELL_PRED_PROP_VOLUME_COOPS = predict(stg1_mfit, data=stg1_predict)$predictions

stg1_predict$CELL_PRED_PROP_VOLUME_COOPS %>% summary()

cells = 
  cells %>% 
  left_join(stg1_predict %>% select(CELL_ID, CELL_PRED_PROP_VOLUME_COOPS), 
            by = "CELL_ID") %>% 
  # this left NAs in cells not in the predict set, i.e. in the development set
  mutate(CELL_PRED_PROP_VOLUME_COOPS = case_when(
    is.na(CELL_PRED_PROP_VOLUME_COOPS) ~ CELL_PROP_VOLUME_COOPS, 
    TRUE ~ CELL_PRED_PROP_VOLUME_COOPS
  ))

cells$CELL_PRED_PROP_VOLUME_COOPS %>% summary()

# at this stage, the NAs come from CELL_PROP_VOLUME_COOPS, in cells with no potential link at all 
stopifnot(cells %>% filter(is.na(CELL_PRED_PROP_VOLUME_COOPS)) %>% pull(CELL_NO_POTENTIAL_LINK) %>% all())

```

- TAKES TOO MUCH TIME, check how to improve efficiency 
```{r}
stg2_predict = links

stg2_predict$LINK_PRED_EXIST_PROB = predict(stg2_mfit, 
                                            new_data=stg2_predict, 
                                            type = "prob")$`.pred_Actual_links`
  

stg2_predict$LINK_PRED_EXIST_PROB %>% summary()

cells = 
  cells %>% 
  left_join(stg2_predict %>% select(CELL_ID, CELL_PRED_PROP_VOLUME_COOPS), 
            by = "CELL_ID") %>% 
  # this left NAs in cells not in the predict set, i.e. in the development set
  mutate(CELL_PRED_PROP_VOLUME_COOPS = case_when(
    is.na(CELL_PRED_PROP_VOLUME_COOPS) ~ CELL_PROP_VOLUME_COOPS, 
    TRUE ~ CELL_PRED_PROP_VOLUME_COOPS
  ))

cells$CELL_PRED_PROP_VOLUME_COOPS %>% summary()

# at this stage, the NAs come from CELL_PROP_VOLUME_COOPS, in cells with no potential link at all 
stopifnot(cells %>% filter(is.na(CELL_PRED_PROP_VOLUME_COOPS)) %>% pull(CELL_NO_POTENTIAL_LINK) %>% all())






```