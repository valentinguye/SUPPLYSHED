---
title: "model"
author: "Valentin"
date: "`r Sys.Date()`"
output: 
  html_document:
      self_contained: false
---
# Set up and inputs
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

library(aws.s3)
aws.signature::use_credentials()
Sys.setenv("AWS_DEFAULT_REGION" = "eu-west-1")


library(tidyverse)
library(sf)
library(readxl)
library(xlsx)
library(stringr)
library(DescTools)
library(rnaturalearth)
library(ggpubr)
library(units)
library(scales)
library(kableExtra)
library(here)
library(readstata13)
library(sjmisc)
library(terra) # put it after {raster} such that it superceeds homonym functions. 
library(exactextractr)
library(stars)
library(pals)
library(modelsummary) # necessary to load it after DescTools

# ML libraries
library(ranger)
library(parsnip)
library(xgboost)
library(pROC)
library(yardstick)

library(familiar)
# and packages required but some uses of familiar: 
library(microbenchmark)
library(glmnet)
library(fastcluster)
library(praznik)
library(power.transform)
library(isotree)
library(laGP)
library(harmonicmeanp)
library(mboost)

set.seed(8888)

# install.packages("https://cran.r-project.org/src/contrib/Archive/isotree/isotree_0.5.5.tar.gz",
#                  repos = NULL, 
#                  type = "source")

dir.create(here("temp_data", "familiar", "stage_1"))
dir.create(here("temp_data", "familiar", "stage_2"))

## Functions
# Trase palettes etc. for plots
source(here("code", "theme_trase.R"))

# load in particular the function fn_trader_to_group_names, str_trans, ... 
source(here("code", "USEFUL_STUFF_supplyshedproj.R"))

# use the projected CRS used by BNETD for their 2020 land use map. 
civ_crs <- 32630

MODEL_RESOLUTION_KM = 4

xlabs = c(-8, -6, -4)
ylabs = c(5, 7, 9)

## Assets

# coopbsy = read.csv(file = here("temp_data/private_IC2B/IC2B_v2_coop_bs_year.csv")) 

consol = readRDS(here("temp_data", "actual_links_consolidated.Rdata"))

cells = readRDS(here("temp_data", "prepared_main_dataset", paste0("cell_", MODEL_RESOLUTION_KM, "km.Rdata"))) 

links = readRDS(here("temp_data", "prepared_main_dataset", paste0("cell_links_", MODEL_RESOLUTION_KM, "km.Rdata")))

departements <- read_sf(here("input_data/s3/CIV_DEPARTEMENTS.geojson"))
departements = 
  st_transform(departements, crs = civ_crs)

cells = 
  cells %>% 
  rename(CELL_PROP_COOP_STATUS_COOPCA = `CELL_PROP_COOP_STATUS_COOP-CA`, 
         CELL_PROP_1_NEAREST_COOP_STATUS_COOPCA = `CELL_PROP_1_NEAREST_COOP_STATUS_COOP-CA`, 
         CELL_PROP_5_NEAREST_COOP_STATUS_COOPCA = `CELL_PROP_5_NEAREST_COOP_STATUS_COOP-CA`)

links = 
  links %>% 
  rename(COOP_STATUS_COOPCA = `COOP_STATUS_COOP-CA`,
         COOP_DISTRICT_SAN_PEDRO = `COOP_DISTRICT_SAN-PEDRO`,
         COOP_DISTRICT_GRAND_LAHOU = `COOP_DISTRICT_GRAND-LAHOU`,
         COOP_DISTRICT_YAKASSE_ATTOBROU = `COOP_DISTRICT_YAKASSE-ATTOBROU`,
         COOP_DISTRICT_ZOUAN_HOUNIEN = `COOP_DISTRICT_ZOUAN-HOUNIEN`,
         COOP_DISTRICT_KOUN_FAO = `COOP_DISTRICT_KOUN-FAO`,
         COOP_DISTRICT_GRAND_BASSAM = `COOP_DISTRICT_GRAND-BASSAM`, 
         COOP_DISTRICT_MBATTO = `COOP_DISTRICT_M'BATTO`)

# Make target a factor
links = 
  links %>% 
  mutate(LINK_IS_ACTUAL_COOP_class = factor(if_else(LINK_IS_ACTUAL_COOP, "Actual links", "Virtual links"), 
                                               levels = c("Virtual links", "Actual links"))) 

```

## Remove some cell/link categories 
```{r}
# Remove cells outside in-land territory
# cells %>% filter(is.na(CELL_DISTRICT_NAME)) %>% pull(SPLIT) %>% unique()
# cells %>% filter(is.na(CELL_DISTRICT_NAME)) %>% nrow()
cells = 
  cells %>% 
  filter(!is.na(CELL_DISTRICT_NAME))

links = 
  links %>% 
  filter(!is.na(CELL_DISTRICT_NAME))

# In addition, from links, we also remove: 
links =
  links %>%
  # Remove links with non-IC2B coops or with other buyers, 
  # because they would count as FALSE on LINK_IS_ACTUAL_COOP, the target var, while not being exactly what we are after
  filter(!LINK_IS_ACTUAL_OTHER) %>% 
  # Remove empty links that only represent cells from where no coop is reachable. 
  # We are not interested in describing, learning from, or predicting in these cells. We will recollect them post-estimation
  filter(!CELL_NO_POTENTIAL_LINK)

stopifnot(links %>% 
            filter(!LINK_IS_VIRTUAL) %>% nrow() == sum(links$LINK_IS_ACTUAL_COOP))
```


# EXTRACT TRAIN/TEST SETS
Any processing on explanatory features' values should be made before this step. 
```{r}
cells = 
  cells %>% 
  mutate(SPLIT = if_else(CELL_VOLUME_OBSERVED, "Train/test set", "No data")) 

stg1_traintest =
  cells %>%
  filter(SPLIT == "Train/test set") 

links = 
  links %>% 
  mutate(SPLIT = if_else(CELL_ACTUAL_LINK & !CELL_ACTUAL_ONLYOTHER_LINK, "Train/test set", "No data")) 

stg2_traintest =
  links %>%
  filter(SPLIT == "Train/test set") 

```



# DESCRIPTIVES 
## Cells des. stats.

### Structure of the cell data
```{r}
# How many cells with actual links
# cells %>% 
#   select(!starts_with("CELL_PROP") & !starts_with("CELL_COUNT")) %>% 
#   datasummary_skim()

cells = 
  cells %>% 
  mutate(CELL_2ND_STAGE_ONLY = CELL_ANY_ACTUAL_COOP_LINK & !CELL_VOLUME_OBSERVED, 
         CELL_NO_ACTUAL_LINK_DATA = CELL_ONLY_VIRTUAL_LINK | (!CELL_ONLY_VIRTUAL_LINK & 
                                                              CELL_ACTUAL_ONLYOTHER_LINK & 
                                                              !CELL_VOLUME_OBSERVED))
# nocat = 
#   cells %>%
#   filter(!CELL_NO_POTENTIAL_LINK & !CELL_NO_ACTUAL_LINK_DATA & !CELL_2ND_STAGE_ONLY & !CELL_VOLUME_OBSERVED) %>% 
#   View()
# cell_ids_check = nocat$CELL_ID
# links %>% filter(CELL_ID %in% cell_ids_check) %>% 
#   pull(CELL_ACTUAL_ONLYOTHER_LINK) %>% summary()

# export
(datasummary(N + Percent()  ~ 
              (`No buying station within 72 km` = (CELL_NO_POTENTIAL_LINK==T)) + 
              (`No actual link data` = (CELL_NO_ACTUAL_LINK_DATA==T)) + 
              (`Actual link data for 2nd stage only` = (CELL_2ND_STAGE_ONLY==T)) + 
              (`Actual link data for 1st stage` = (CELL_VOLUME_OBSERVED==T)) + 
              1, 
              data = cells,
              fmt = 1,
              align = "cccccc",
              output = here("outputs", paste0("cells_",MODEL_RESOLUTION_KM,"km_destat.png"))))
# Cells with actual link data for both stages have JRC or SC data on actual link existence, size and type of buyer (cooperative or other), that is representative for the whole cell. 

# ?tables::Heading

cells %>% filter(SPLIT == "Train/test set") %>% nrow()

```

### Map of the cell data
```{r}
toplot = 
  cells %>% 
  st_as_sf(coords = c("CELL_LONGITUDE", "CELL_LATITUDE"), crs = 4326) %>% 
  st_transform(civ_crs) %>% 
    mutate(
      `Cell information content` = case_when(
        CELL_NO_POTENTIAL_LINK ~ "No buying station within 72 km", 
        CELL_NO_ACTUAL_LINK_DATA ~ "No actual link data",
        CELL_VOLUME_OBSERVED ~ "Actual link data for 1st stage",
        CELL_2ND_STAGE_ONLY ~ "Actual link data for second stage only",
      )) 
toplot$`Cell information content` %>% table()    


ggplot(toplot) +
    geom_sf(aes(col = `Cell information content`), shape = 15) + 
    geom_sf(data = departements, fill = "transparent", col = "black") +
    # scale_colour_brewer(na.value = NULL,
    #                     type = "qual",
    #                     direction = -1,
    #                     palette = "Set3") +
  scale_colour_manual(
    values = c("#E763DF" , "#639DE6", "lightgrey", "darkgrey")
  ) +
  # labs(fill = "Extent of the Ivorian cocoa growing region") + 
    theme_minimal() + 
    scale_x_continuous(breaks = xlabs, labels = paste0(xlabs,'°W')) +
    scale_y_continuous(breaks = ylabs, labels = paste0(ylabs,'°N'))
    
```


### Cell data features
In the train/test set 
```{r}
# names(cells)

cells_traintest_features =
  cells %>% 
  select(Sample = SPLIT, 
         `Cooperative outlet share` = CELL_PROP_VOLUME_COOPS, 
         `Cocoa output from cell (kg)` = CELL_VOLUME_KG,
         `# BS within 72km` = CELL_N_BS_WITHIN_DIST, 
         `Avg. distance of the 5 nearest BS (m)` = CELL_AVG_DISTANCE_METERS_5_NEAREST_COOPS, 
         `# registered licensed buyers in department` = CELL_AVG_N_LICBUY_IN_DPT, 
         `Cocoa extent (ha)` = CELL_COCOA_HA,
         `Settlements extent (ha)` = CELL_SETTLEMENT_HA,
         `Terrain Ruggedness Index (mm)` = CELL_TRI_MM,
         `Proportion of 5 nearest cooperatives certified` = CELL_PROP_5_NEAREST_COOP_CERTIFIED,
         `Proportion of 5 nearest cooperatives with SSIs` = CELL_PROP_5_NEAREST_COOP_HAS_SSI,
         `Proportion of 5 nearest cooperatives with CCP` = CELL_PROP_5_NEAREST_COOP_SSI_CARGILL,
         `Proportion of 5 nearest cooperatives being COOP-CA` = CELL_PROP_5_NEAREST_COOP_STATUS_SCOOPS,
         `Proportion of 5 nearest cooperatives being SCOOPS` = `CELL_PROP_5_NEAREST_COOP_STATUS_COOPCA`,
         `Total # members of 5 nearest cooperatives` = CELL_COUNT_5_NEAREST_COOP_FARMERS,
         `Total # BS of 5 nearest cooperatives` = CELL_COUNT_5_NEAREST_COOP_N_KNOWN_BS,
         `Avg. # buying companies in 5 nearest cooperatives` = CELL_AVG_5_NEAREST_COOP_N_KNOWN_BUYERS,
         `Avg. TRI around 5 nearest cooperatives (mm)` = CELL_AVG_5_NEAREST_COOP_BS_10KM_TRI,
         `Avg. cocoa extent around 5 nearest cooperatives (ha)` = CELL_AVG_5_NEAREST_COOP_BS_10KM_COCOA_HA,
         `Avg. settlements extent around 5 nearest cooperatives` = CELL_AVG_5_NEAREST_COOP_BS_10KM_SETTLEMENT_HA
         ) %>% 
    filter(Sample == "Train/test set")


(datasummary_skim(data = cells_traintest_features, 
                 output = here("outputs", paste0("cells_",MODEL_RESOLUTION_KM,"km_train_features.html"))))

```

Cell data balance tests
```{r}
# (datasummary_balance(~SPLIT, 
#                       data = cells_features_tobalance, 
#                       stars = TRUE,
#                       # title = "Summaries and balance tests on cell data sets to train/test and to predict the cell share of cooperative outlet", 
#                       notes = "'BS' stands for cooperative buying stations.", 
#                      output = here("outputs", "cells_balance.png")))        
```


## Links descriptive statistics

### Features in the Potential-links data  
With differences between actual and/virtual in train/test? 

(Alternatively, we could look at: 
- Only in actual 
- Between train/test and predict sets)

```{r}
names(stg2_traintest)
stg2_features_tobalance_1 =
  stg2_traintest %>%
  mutate(across(where(is.logical), as.integer)) %>% 
  select(LINK_IS_ACTUAL_COOP_class, 
         LINK_DISTANCE_METERS,
         LINK_IS_WITH_1_NEAREST_COOPS,
         LINK_IS_WITH_5_NEAREST_COOPS,
         CELL_N_BS_WITHIN_DIST,
         CELL_N_COOP_IN_DPT, CELL_AVG_N_LICBUY_IN_DPT,
         CELL_COCOA_HA, CELL_SETTLEMENT_HA, CELL_TRI_MM)

datasummary_balance(~LINK_IS_ACTUAL_COOP_class, 
                    data = stg2_features_tobalance_1, 
                    output = here("outputs", paste0("stg2_",MODEL_RESOLUTION_KM,"km_features.png")))

stg2_features_tobalance_2 =
  stg2_traintest %>%
  mutate(across(where(is.logical), as.integer)) %>% 
  select(LINK_IS_ACTUAL_COOP_class,
         COOP_FARMERS, 
         COOP_N_KNOWN_BUYERS, COOP_N_KNOWN_BS,
         starts_with("COOP_STATUS_"), 
         COOP_CERTIFIED, COOP_RFA, COOP_UTZ, COOP_FT, 
         COOP_HAS_SSI, starts_with("COOP_SSI_"), 
         starts_with("COOP_BS_10KM_"))

datasummary_balance(~LINK_IS_ACTUAL_COOP_class, 
                    data = stg2_features_tobalance_2)

```



# FIRST STAGE 


## Data and formula


Resources on data split here: https://encord.com/blog/train-val-test-split/
```{r}
# Here, we do not do holdout method, so we do not split data into train and test sets. 
anyNA(stg1_traintest)

stg1_predict = 
  cells %>% 
  filter(!CELL_NO_POTENTIAL_LINK)

# names(cells)
# anyNA(cells)
stg1_allfeatures = 
  cells %>% 
  select(
    ends_with("_HA"), CELL_TRI_MM, 
    CELL_N_BS_WITHIN_DIST, CELL_N_COOP_IN_DPT, CELL_AVG_N_LICBUY_IN_DPT,
    CELL_AVG_DISTANCE_METERS_5_NEAREST_COOPS, CELL_MIN_DISTANCE_METERS,
    starts_with("CELL_PROP_5_NEAREST"), 
    starts_with("CELL_AVG_5_NEAREST"), 
    starts_with("CELL_COUNT_5_NEAREST")) %>% 
  names() 
  

stg1_mformula_allfeatures = as.formula(paste0("CELL_PROP_VOLUME_COOPS ~ ", paste0(stg1_allfeatures, collapse = " + ")))

```


## Everything FAMILIAR
For warm starts: 
precompute_data_assignment --> An experimentData object.
precompute_feature_info    --> An experimentData object.
precompute_vimp            --> An experimentData object.
(each does additional steps)

predict function like anywhere else. 
```{r}
# ?train_familiar
# ?theme_familiar
# ?summon_familiar
# ?as_familiar_data
# ?predict  

anyNA(stg1_traintest)


summon_familiar(
  
  formula = stg1_mformula_allfeatures,
  data = stg1_traintest,
  experiment_dir = here("temp_data", "familiar", "stage_1"),
  sample_id_column = "CELL_ID",
  outcome_name = "Cooperative outlet share",
  outcome_column = "CELL_PROP_VOLUME_COOPS",
  outcome_type = "continuous",
  experimental_design = "cv(bt(fs,100) + mb, 5)",
  # imbalance_correction_method = "random_undersampling", # do not specify, to avoid any kind of under-sampling, since we did it in external pre-processing.  
  parallel = TRUE, # The default is TRUE, but unnecessary in 1st stage at least. Actually it IS! 
  parallel_nr_cores = detectCores() - 2, # 2 is the default, and UCLouvain machine has 8, in case we need to increase. 
  
  # PRE-PROCESSING ARGS
  # (not all "none" are the defaults)
  filter_method = "none", # no feature to be filtered in pre-processing
  transformation_method = "none", 
  normalisation_method = "none",
  cluster_method = "hclust", # default:hclust. This is categorised in data processing, but it will affect feature selection. 
  # imputation_method does not matter bc we have no NA. 
  
  
  # FEATURE SELECTION & OPTIMIZATION 
  fs_method = "random_forest_ranger_permutation", # see https://cran.r-project.org/web/packages/familiar/vignettes/feature_selection_precompiled.html
  # fs_method_parameter = list("random_forest_ranger_permutation" = list()), # this would need to have this format, but let it unspecified, so that feature selection optimizes on ALL hyper-parameters. 
  # vimp_aggregation_method = "borda", # borda is the default. Check guidance to depart. 
  
  learner = "random_forest_ranger",
  # hyperparameter = list("ranger" = list()), #  "If no parameters are provided, sequential model-based optimisation is used to determine optimal hyperparameters."
  
  # EVALUATION INFERENCE
  detail_level = "hybrid", # the default. See ?summon_familiar and  https://cran.r-project.org/web/packages/familiar/vignettes/evaluation_and_explanation_precompiled.html
  estimation_type = "point" # "bootstrap_confidence_interval", # the default. Requires several point estimates. 
  
)


```



## Model fit 
```{r}
stg1_mfit = ranger(data = stg1_traintest, 
                   importance = 'permutation', 
                   case.weights = "CELL_REPRESENTATIVITY_STD_WEIGHT",
                   formula = stg1_mformula_allfeatures, 
                   seed = 8888
                   )
print(stg1_mfit)

```

## Evaluation 
```{r}
test_predictions <- predict(stg1_mfit, data=stg1_test)

stg1_test$CELL_PROP_VOLUME_COOPS_PRED = test_predictions$predictions

stg1_mfit$r.squared
stg1_mfit$prediction.error %>% sqrt()

```



## Predict 
```{r}
stg1_predict$CELL_PRED_PROP_VOLUME_COOPS = predict(stg1_mfit, data=stg1_predict)$predictions

stg1_predict$CELL_PRED_PROP_VOLUME_COOPS %>% summary()

cells = 
  cells %>% 
  left_join(stg1_predict %>% select(CELL_ID, CELL_PRED_PROP_VOLUME_COOPS), 
            by = "CELL_ID") %>% 
  # this left NAs in cells not in the predict set, i.e. in the train/test set
  mutate(CELL_PRED_PROP_VOLUME_COOPS = case_when(
    is.na(CELL_PRED_PROP_VOLUME_COOPS) ~ CELL_PROP_VOLUME_COOPS, 
    TRUE ~ CELL_PRED_PROP_VOLUME_COOPS
  ))

cells$CELL_PRED_PROP_VOLUME_COOPS %>% summary()

# at this stage, the NAs come from CELL_PROP_VOLUME_COOPS, in cells with no potential link at all 
stopifnot(cells %>% filter(is.na(CELL_PRED_PROP_VOLUME_COOPS)) %>% pull(CELL_NO_POTENTIAL_LINK) %>% all())

```


# SECOND STAGE 

## Apply sub-sampling
```{r}
links_ss = 
  links %>% 
  filter(!LINK_POSSIBLE_FALSENEG) %>% 
  filter(LINK_TO_KEEP_TO_US_VIRTUAL) # this is only TRUE currently. 
```



## Data split
Resources on data split here: https://encord.com/blog/train-val-test-split/
```{r}
training_size <- 0.8

# Split the data
stg2_traintest =
  links_ss %>%
  filter(SPLIT == "Train/test set") 

stg2_training =
  stg2_traintest %>%
  slice_sample(prop = training_size) 

stg2_test =
  stg2_traintest %>%
  filter(!LINK_ID %in% stg2_training$LINK_ID) 


stg2_predict = links

```


## Feature selection
Use Boruta here https://cran.r-project.org/web/packages/Boruta/Boruta.pdf
```{r}
# names(links_ss)
anyNA(links_ss)

stg2_allfeatures = 
  links_ss %>% 
  select(
    ends_with("_HA"), CELL_TRI_MM, 
    CELL_N_BS_WITHIN_DIST, # CELL_N_COOP_IN_DPT, CELL_AVG_N_LICBUY_IN_DPT,
    # CELL_AVG_DISTANCE_METERS_5_NEAREST_COOPS, CELL_MIN_DISTANCE_METERS,
    LINK_DISTANCE_METERS,
    starts_with("COOP_FARMERS"), 
    COOP_N_KNOWN_BUYERS, COOP_N_KNOWN_BS,
    COOP_RFA, COOP_UTZ, COOP_FT,
    starts_with("COOP_CERTIFIED"), 
    COOP_HAS_SSI, 
    starts_with("COOP_SSI_"), 
    starts_with("COOP_DISTRICT_"), -COOP_DISTRICT_NAME,
    starts_with("COOP_STATUS_"), 
    starts_with("COOP_BS_10KM")
    ) %>% 
  names() 
  
grep("'", stg2_allfeatures, value = T)

stg2_mformula_allfeatures = as.formula(paste0("LINK_IS_ACTUAL_COOP_class ~ ", paste0(stg2_allfeatures, collapse = " + ")))


```

## Model fit 
```{r}

stg2_mfit =
  boost_tree(
    mode = "classification",
    mtry = 6,
    trees = 5,
    min_n = 5
  ) %>%
  fit(data = stg2_training,
      formula = stg2_mformula_allfeatures)

# stg2mfit = 
#   xgboost(
#   label = stg2_training %>% select(LINK_IS_ACTUAL_COOP_class) %>% as.matrix(), 
#   data = stg2_training %>% select(-LINK_IS_ACTUAL_COOP_class), 
#   nrounds = 6
# )


```

## Evaluation 
```{r}
(test_pred_prob <- predict(stg2_mfit, 
                             new_data=stg2_test, 
                             type = "prob"))

stg2_test$LINK_PRED_ACTUAL_COOP_prob = test_pred_prob$`.pred_Actual links`


(test_pred_class <- predict(stg2_mfit, 
                             new_data=stg2_test, 
                             type = "class")) # this implements a 50% threshold, 
# i.e., if the predicted link is more likely to exist than to not exist, the prediction is classified as "Actual link" 
stg2_test$LINK_PRED_ACTUAL_COOP_class = test_pred_class$.pred_class

stg2_test = 
  stg2_test %>% 
  mutate(TP = LINK_PRED_ACTUAL_COOP_class == "Actual links"  & LINK_IS_ACTUAL_COOP_class == "Actual links",
         TN = LINK_PRED_ACTUAL_COOP_class == "Virtual links" & LINK_IS_ACTUAL_COOP_class == "Virtual links",
         FP = LINK_PRED_ACTUAL_COOP_class == "Actual links"  & LINK_IS_ACTUAL_COOP_class == "Virtual links",
         FN = LINK_PRED_ACTUAL_COOP_class == "Virtual links" & LINK_IS_ACTUAL_COOP_class == "Actual links")


```

### Accuracy 
we can calculate the overall accuracy score as a sum of instances where predicted and actual classes match divided by the total number of rows:
```{r}

(accuracy = sum(stg2_test$LINK_PRED_ACTUAL_COOP_class == stg2_test$LINK_IS_ACTUAL_COOP_class) / nrow(stg2_test))
(accuracy = (sum(stg2_test$TP) + sum(stg2_test$TN) ) / (sum(stg2_test$TP) + sum(stg2_test$TN)  + sum(stg2_test$FP) + sum(stg2_test$FN)))

```

### True Positive Rate (Recall) 
```{r}
(recall = sum(stg2_test$TP) / (sum(stg2_test$TP) + sum(stg2_test$FN)))
```

### False Negative Rate (probability of false alarm)
```{r}
(fpr = sum(stg2_test$FP) / (sum(stg2_test$TN) + sum(stg2_test$FP)))
```

### Precision
```{r}
(precision = sum(stg2_test$TP) / (sum(stg2_test$TP) + sum(stg2_test$FP)))

```


### Confusion Matrix  
```{r}
# This requires package caret which fails to install. 
# cm = confusionMatrix(stg2_test$LINK_IS_ACTUAL_COOP_class, stg2_test$LINK_PRED_ACTUAL_COOP_class)
# 
# 
# # Plot it 
# cfm <- as_tibble(cm$table)
# plot_confusion_matrix(cfm, target_col = "Reference", prediction_col = "Prediction", counts_col = "n")

```

### PR-CURVE
```{r}
prc_xgboost_test = 
  pr_curve(
    data = stg2_test, 
    truth = LINK_IS_ACTUAL_COOP_class,
    LINK_PRED_ACTUAL_COOP_prob, 
    event_level = "second"
)

(PRAUC = 
  pr_auc(
    data = stg2_test, 
    truth = LINK_IS_ACTUAL_COOP_class,
    LINK_PRED_ACTUAL_COOP_prob, 
    event_level = "second",
    estimator = "binary"
))

ggplot(prc_xgboost_test, aes(x = recall, y = precision)) +
  geom_path() +
  coord_equal() +
  theme_bw()  
  # legend(legend = c(paste0("Main model \nAUC = ",round(PRAUC, 2))))
  
```

### AUROC
```{r}
roc_xgboost_test = 
  roc(
  data = stg2_test, 
  response = LINK_IS_ACTUAL_COOP_class,
  predictor = LINK_PRED_ACTUAL_COOP_prob,
  quiet = TRUE
)

(AUC = roc_xgboost_test$auc)

plot(pROC::smooth(roc_xgboost_test), col = "blue", lwd = 1) 
legend(
  "bottomright",
  col = "blue",
  lwd = 1,
  legend = c(paste0("Main model \nAUC = ",round(AUC, 2)))
)
```


## Predict
- TAKES TOO MUCH TIME, check how to improve efficiency 
```{r}
stg2_predict$LINK_PRED_EXIST_PROB = predict(stg2_mfit, 
                                            new_data=stg2_predict, 
                                            type = "prob")$`.pred_Actual links`
  

stg2_predict$LINK_PRED_EXIST_PROB %>% summary()

cells = 
  cells %>% 
  left_join(stg2_predict %>% select(CELL_ID, CELL_PRED_PROP_VOLUME_COOPS), 
            by = "CELL_ID") %>% 
  # this left NAs in cells not in the predict set, i.e. in the train/test set
  mutate(CELL_PRED_PROP_VOLUME_COOPS = case_when(
    is.na(CELL_PRED_PROP_VOLUME_COOPS) ~ CELL_PROP_VOLUME_COOPS, 
    TRUE ~ CELL_PRED_PROP_VOLUME_COOPS
  ))

cells$CELL_PRED_PROP_VOLUME_COOPS %>% summary()

# at this stage, the NAs come from CELL_PROP_VOLUME_COOPS, in cells with no potential link at all 
stopifnot(cells %>% filter(is.na(CELL_PRED_PROP_VOLUME_COOPS)) %>% pull(CELL_NO_POTENTIAL_LINK) %>% all())






```