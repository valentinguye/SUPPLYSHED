---
title: "model"
author: "Valentin"
date: "`r Sys.Date()`"
output: 
  html_document:
      self_contained: false
---
# Set up and inputs
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

library(aws.s3)
aws.signature::use_credentials()
Sys.setenv("AWS_DEFAULT_REGION" = "eu-west-1")


library(tidyverse)
library(sf)
library(readxl)
library(xlsx)
library(stringr)
library(DescTools)
library(rnaturalearth)
library(ggpubr)
library(units)
library(scales)
library(kableExtra)
library(here)
library(readstata13)
library(sjmisc)
library(terra) # put it after {raster} such that it superceeds homonym functions. 
library(exactextractr)
library(stars)
library(pals)
library(modelsummary) # necessary to load it after DescTools

# ML libraries
library(ranger)
library(parsnip)
library(xgboost)
library(pROC)
library(yardstick)

library(familiar)
# and packages required but some uses of familiar: 
library(microbenchmark)
library(glmnet)
library(fastcluster)
library(praznik)
library(power.transform)
library(isotree)
library(laGP)
library(harmonicmeanp)
library(mboost)

set.seed(8888)

# install.packages("https://cran.r-project.org/src/contrib/Archive/isotree/isotree_0.5.5.tar.gz",
#                  repos = NULL, 
#                  type = "source")

# These are were summon_familiar will write its outputs
dir.create(here("temp_data", "familiar", "stage_1"))
dir.create(here("temp_data", "familiar", "stage_2"))
# This is to save some of the outputs from being overwritten subsequently. 
dir.create(here("outputs", "familiar", "stage_1", "performance"), recursive = TRUE)
dir.create(here("outputs", "familiar", "stage_1", "explanation_vimp"), recursive = TRUE)
dir.create(here("outputs", "familiar", "stage_2", "performance"), recursive = TRUE)
dir.create(here("outputs", "familiar", "stage_2", "explanation_vimp"), recursive = TRUE)

# And to save the predictions 
dir.create(here("temp_data", "predictions", "stage_1"))
dir.create(here("temp_data", "predictions", "stage_2"))

## Functions
# Trase palettes etc. for plots
source(here("code", "theme_trase.R"))

# load in particular the function fn_trader_to_group_names, str_trans, ... 
source(here("code", "USEFUL_STUFF_supplyshedproj.R"))

# use the projected CRS used by BNETD for their 2020 land use map. 
civ_crs <- 32630

MODEL_RESOLUTION_KM = 4
cell_area_ha =(100*MODEL_RESOLUTION_KM^2)

xlabs = c(-8, -6, -4)
ylabs = c(5, 7, 9)

## Assets

coopbsy = read.csv(file = here("temp_data/private_IC2B/IC2B_v2_coop_bs_year.csv"))
coopbs22 = coopbsy %>% filter(YEAR == 2022)

consol = readRDS(here("temp_data", "actual_links_consolidated.Rdata"))

cells = readRDS(here("temp_data", "prepared_main_dataset", paste0("cell_", MODEL_RESOLUTION_KM, "km.Rdata"))) 

links = readRDS(here("temp_data", "prepared_main_dataset", paste0("cell_links_", MODEL_RESOLUTION_KM, "km.Rdata")))

departements <- read_sf(here("input_data/s3/CIV_DEPARTEMENTS.geojson"))
departements = 
  st_transform(departements, crs = civ_crs)

```

# Useful pre-ops
## Cols ops
```{r}
cells = 
  cells %>% 
  rename(CELL_PROP_COOP_STATUS_COOPCA = `CELL_PROP_COOP_STATUS_COOP-CA`, 
         CELL_PROP_1_NEAREST_COOP_STATUS_COOPCA = `CELL_PROP_1_NEAREST_COOP_STATUS_COOP-CA`, 
         CELL_PROP_5_NEAREST_COOP_STATUS_COOPCA = `CELL_PROP_5_NEAREST_COOP_STATUS_COOP-CA`) %>% 
  # this is just for descriptives a priori
  mutate(CELL_2ND_STAGE_ONLY = CELL_ANY_ACTUAL_COOP_LINK & !CELL_VOLUME_OBSERVED, 
         CELL_NO_ACTUAL_LINK_DATA = CELL_ONLY_VIRTUAL_LINK | (!CELL_ONLY_VIRTUAL_LINK & 
                                                              CELL_ACTUAL_ONLYOTHER_LINK & 
                                                              !CELL_VOLUME_OBSERVED))

links = 
  links %>% 
  rename(COOP_STATUS_COOPCA = `COOP_STATUS_COOP-CA`,
         COOP_DISTRICT_SAN_PEDRO = `COOP_DISTRICT_SAN-PEDRO`,
         COOP_DISTRICT_GRAND_LAHOU = `COOP_DISTRICT_GRAND-LAHOU`,
         COOP_DISTRICT_YAKASSE_ATTOBROU = `COOP_DISTRICT_YAKASSE-ATTOBROU`,
         COOP_DISTRICT_ZOUAN_HOUNIEN = `COOP_DISTRICT_ZOUAN-HOUNIEN`,
         COOP_DISTRICT_KOUN_FAO = `COOP_DISTRICT_KOUN-FAO`,
         COOP_DISTRICT_GRAND_BASSAM = `COOP_DISTRICT_GRAND-BASSAM`, 
         COOP_DISTRICT_MBATTO = `COOP_DISTRICT_M'BATTO`)

# Make target a factor
links = 
  links %>% 
  mutate(LINK_IS_ACTUAL_COOP_class = factor(if_else(LINK_IS_ACTUAL_COOP, "Actual links", "Virtual links"), 
                                               levels = c("Virtual links", "Actual links"))) 

# Make COOP (and not Buying station) ID: 
links = 
  links %>% 
  mutate(LINK_ACTUAL_COOP_ID = gsub("_BS.*", "", LINK_ACTUAL_COOP_BS_ID), 
         LINK_POTENTIAL_COOP_ID = gsub("_BS.*", "", LINK_POTENTIAL_COOP_BS_ID))

```

## Remove cell & link instances 
```{r}
# Remove cells with no district (very few since we already removed cells outside inland territory in data preparation)
# cells %>% filter(is.na(CELL_DISTRICT_NAME)) %>% pull(SPLIT) %>% unique()
# cells %>% filter(is.na(CELL_DISTRICT_NAME)) %>% nrow()
cells = 
  cells %>% 
  # Remove the few cells that still fall in no district 
  filter(!is.na(CELL_DISTRICT_NAME)) 

  # Removing the cells where there is little cocoa (less than 1%) and lots of land where cocoa cannot expand (more than 90%
  # does not make a big difference (80 cells). So let's not remove them. It's a display issue. In terms of results, we will anyway aggregate cocoa or forest area 
  # filter(!(CELL_COCOA_HA / cell_area_ha < 0.01 & CELL_IMPOSSIBLE_HA / cell_area_ha > 0.9))

links = 
  links %>% 
  # Remove the few cells that still fall in no district 
  filter(!is.na(CELL_DISTRICT_NAME))
  

# In addition, from links, we also remove: 
links =
  links %>%
  # Remove links with non-IC2B coops or with other buyers, 
  # because they would count as FALSE on LINK_IS_ACTUAL_COOP, the target var, while not being exactly what we are after
  filter(!LINK_IS_ACTUAL_OTHER) %>% 
  # Remove empty links that only represent cells from where no coop is reachable. 
  # We are not interested in describing, learning from, or predicting in these cells. We will recollect them post-estimation
  filter(!CELL_NO_POTENTIAL_LINK)

stopifnot(links %>% 
            filter(!LINK_IS_VIRTUAL) %>% nrow() == sum(links$LINK_IS_ACTUAL_COOP))
```

## Under-sample virtual links
```{r}
links_us = 
  links %>% 
  filter(!LINK_POSSIBLE_FALSENEG) %>% 
  filter(LINK_TO_KEEP_TO_US_VIRTUAL) # this is only TRUE currently. 
```

## Extract development sets
Any processing on explanatory features' values should be made before this step so it is done once for all the data
```{r}
cells = 
  cells %>% 
  mutate(SPLIT = if_else(CELL_VOLUME_OBSERVED, "Development set", "No data")) 

stg1_development =
  cells %>% filter(SPLIT == "Development set") 

links_us = 
  links_us %>% 
  mutate(SPLIT = if_else(CELL_ACTUAL_LINK & !CELL_ACTUAL_ONLYOTHER_LINK, "Development set", "No data")) 

stg2_development =
  links_us %>%
  filter(SPLIT == "Development set") 

cells_stg2_development =
  stg2_development %>%
  distinct(CELL_ID, .keep_all = TRUE) %>% 
  select(starts_with("CELL_"))
  


```



# DESCRIPTIVES 


## Cells data 

### Structure
```{r}
# How many cells with actual links
# cells %>% 
#   select(!starts_with("CELL_PROP") & !starts_with("CELL_COUNT")) %>% 
#   datasummary_skim()

# nocat = 
#   cells %>%
#   filter(!CELL_NO_POTENTIAL_LINK & !CELL_NO_ACTUAL_LINK_DATA & !CELL_2ND_STAGE_ONLY & !CELL_VOLUME_OBSERVED) %>% 
#   View()
# cell_ids_check = nocat$CELL_ID
# links %>% filter(CELL_ID %in% cell_ids_check) %>% 
#   pull(CELL_ACTUAL_ONLYOTHER_LINK) %>% summary()

# export
(datasummary(N + Percent()  ~ 
              (`No buying station within 72 km` = (CELL_NO_POTENTIAL_LINK==T)) + 
              (`No actual link data` = (CELL_NO_ACTUAL_LINK_DATA==T)) + 
              (`Actual link data for 2nd stage only` = (CELL_2ND_STAGE_ONLY==T)) + 
              (`Actual link data for 1st stage` = (CELL_VOLUME_OBSERVED==T)) + 
              1, 
              data = cells,
              fmt = 1,
              align = "cccccc",
              output = here("outputs", "input_data_descriptives", paste0("cells_",MODEL_RESOLUTION_KM,"km_destat.png"))))
# Cells with actual link data for both stages have JRC or SC data on actual link existence, size and type of buyer (cooperative or other), that is representative for the whole cell. 

# ?tables::Heading

stg1_development %>% nrow()

```

### Map
```{r}

# tmptoplot = only_potential_propt %>% filter(!duplicated(CELL_ID))
# tmptoplot_itm = only_potential_itmpt %>% filter(!duplicated(BUYER_LONGITUDE, BUYER_LATITUDE))
# 
# ggplot() +
#   theme_bw() +
#   geom_sf(data = tmptoplot, , size = 0.05, 
#              col = "red") +
#   geom_sf(data = tmptoplot_itm, , size = 1, 
#           col = "blue") +
#     # geom_sf(data = departements, fill = "transparent") +
#     geom_sf(data = civ_boundary, fill = "transparent") 


consol_itm_sf = 
  consol %>% 
  filter(!is.na(BUYER_LONGITUDE) & BUYER_IS_COOP) %>% # This excludes other buyers
  distinct(COOP_BS_ID, .keep_all = TRUE) %>% 
  st_as_sf(coords = c("BUYER_LONGITUDE", "BUYER_LATITUDE"), crs = 4326)

unlinked_coopbs = 
  coopbs22 %>% 
  filter() %>% 
  filter(!is.na(LONGITUDE) & !COOP_BS_ID %in% consol_itm_sf$COOP_BS_ID) %>% # This excludes coops already in observed links data
  distinct(COOP_BS_ID, .keep_all = TRUE) %>% 
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs = 4326)


toplot = 
  cells %>% 
  st_as_sf(coords = c("CELL_LONGITUDE", "CELL_LATITUDE"), crs = 4326) %>% 
  st_transform(civ_crs) %>% 
    mutate(
      `Cell information content` = case_when(
        CELL_NO_POTENTIAL_LINK ~ "No buying station within 72 km", 
        CELL_NO_ACTUAL_LINK_DATA ~ "No actual link data",
        CELL_VOLUME_OBSERVED ~ "Actual link data for 1st stage",
        CELL_2ND_STAGE_ONLY ~ "Actual link data for second stage only",
      )) 
toplot$`Cell information content` %>% table()    


ggplot(toplot) +
    geom_sf(aes(col = `Cell information content`), size = 1) + #, shape = 15
    geom_sf(data = departements, fill = "transparent", col = "black") +
    # scale_colour_brewer(na.value = NULL,
    #                     type = "qual",
    #                     direction = -1,
    #                     palette = "Set3") +
  scale_colour_manual(
    values = c("blue" , "#8B0000", "lightgrey", "darkgrey")
  ) +
  geom_sf(data = consol_itm_sf, size = 1,
          col = "black") +
  geom_sf(data = unlinked_coopbs, size = 0.1,
          col = "black") +
  # scale_size_binned(
  #   values = c(1, 0.1),
  #   labels = c("Coops in observed links data", "Other coops")
  # ) +
  # labs(fill = "Extent of the Ivorian cocoa growing region") + 
    theme_minimal() + 
  theme(legend.key.size = unit(1, "cm")) +
    scale_x_continuous(breaks = xlabs, labels = paste0(xlabs,'°W')) +
    scale_y_continuous(breaks = ylabs, labels = paste0(ylabs,'°N'))
    
ggsave(  
  filename = "input_data_map",
  path = here("outputs", "input_data_descriptives"), 
  width = units(1200, "px"), 
  height = units(800, "px"))

```


### Features
In the development set 
```{r}
# names(cells)

cells_development_features =
  stg1_development %>% 
  select(Sample = SPLIT, 
         `Cooperative outlet share` = CELL_PROP_VOLUME_COOPS, 
         `Cocoa output from cell (kg)` = CELL_VOLUME_KG,
         `# BS within 72km` = CELL_N_BS_WITHIN_DIST, 
         `Avg. road distance of the 1 nearest BS (m)` = CELL_AVG_DISTANCE_METERS_1_NEAREST_COOPS, 
         `Avg. road distance of the 5 nearest BS (m)` = CELL_AVG_DISTANCE_METERS_5_NEAREST_COOPS, 
         `# registered licensed buyers in department` = CELL_AVG_N_LICBUY_IN_DPT, 
          
         `Terrain Ruggedness Index (mm)` = CELL_TRI_MM,
         `Proportion of 5 nearest cooperatives certified` = CELL_PROP_5_NEAREST_COOP_CERTIFIED,
         `Proportion of 5 nearest cooperatives with SSIs` = CELL_PROP_5_NEAREST_COOP_HAS_SSI,
         `Proportion of 5 nearest cooperatives with CCP` = CELL_PROP_5_NEAREST_COOP_SSI_CARGILL,
         `Proportion of 5 nearest cooperatives being COOP-CA` = CELL_PROP_5_NEAREST_COOP_STATUS_SCOOPS,
         `Proportion of 5 nearest cooperatives being SCOOPS` = `CELL_PROP_5_NEAREST_COOP_STATUS_COOPCA`,
         `Total # members of 5 nearest cooperatives` = CELL_COUNT_5_NEAREST_COOP_FARMERS,
         `Total # BS of 5 nearest cooperatives` = CELL_COUNT_5_NEAREST_COOP_N_KNOWN_BS,
         `Avg. # buying companies in 5 nearest cooperatives` = CELL_AVG_5_NEAREST_COOP_N_KNOWN_BUYERS,
         `Avg. TRI around 5 nearest cooperatives (mm)` = CELL_AVG_5_NEAREST_COOP_BS_10KM_TRI,
         `Avg. cocoa extent around 5 nearest cooperatives (ha)` = CELL_AVG_5_NEAREST_COOP_BS_10KM_COCOA_HA,
         `Avg. settlements extent around 5 nearest cooperatives` = CELL_AVG_5_NEAREST_COOP_BS_10KM_SETTLEMENT_HA
         ) 


(datasummary_skim(data = cells_development_features, 
                 output = here("outputs", "input_data_descriptives", paste0("cells_",MODEL_RESOLUTION_KM,"km_train_features.html"))))

```

Cell data balance tests
```{r}
# (datasummary_balance(~SPLIT, 
#                       data = cells_features_tobalance, 
#                       stars = TRUE,
#                       # title = "Summaries and balance tests on cell data sets to development and to predict the cell share of cooperative outlet", 
#                       notes = "'BS' stands for cooperative buying stations.", 
#                      output = here("outputs", "input_data_descriptives", "cells_balance.png")))        
```

### LU 
```{r}
(cells_stg2_development$CELL_COCOA_HA/cell_area_ha) %>% summary()
  
stg1_development %>% 
  select(Sample = SPLIT, 
          `Dense forest extent (ha)` = CELL_DENSEFOREST_HA,
          `other forests extent (ha)` = CELL_OTHERFORESTS_HA,
          `Cocoa extent (ha)` = CELL_COCOA_HA,
          `Coffee extent (ha)` = CELL_COFFEE_HA,
          `Rubber extent (ha)` = CELL_RUBBER_HA,
          `Palm extent (ha)` = CELL_PALM_HA,
          `Coconut extent (ha)` = CELL_COCONUT_HA,
          `Cashew extent (ha)` = CELL_CASHEW_HA,
          `Other agricultural extent (ha)` = CELL_OTHERAG_HA,
          `Settlements extent (ha)` = CELL_SETTLEMENT_HA,
          `Water, rock or infrastructure extent (ha)` = CELL_IMPOSSIBLE_HA
  ) %>% 
  datasummary_skim(output = here("outputs", "input_data_descriptives", paste0("stg1_",MODEL_RESOLUTION_KM,"km_features.html")))

```


## Links data

### Observed links 
This starts from links data, where no under-sampling has been applied (so the biased sampling towards coops is still in there). 
```{r}
obs_links_des = 
  links %>% 
  filter(LINK_IS_ACTUAL) %>% 
  mutate(LINK_SOURCE = case_when(
    grepl("CARGILL", PRO_ID) ~ "Cargill data",
    grepl("SUSTAINCOCOA", PRO_ID) ~ "SC data",
    grepl("JRC", PRO_ID) ~ "JRC data",
  ))

length(unique(na.omit(obs_links_des$LINK_ID_OTHERS)))

totbl = 
  obs_links_des %>% 
  summarise(.by = LINK_SOURCE,  
    # Number of 
    # Links
    `with coops` = length(unique(na.omit(LINK_ID_COOPS))), # if_else(BUYER_IS_COOP, LINK_ID, NA)
    `with others` = length(unique(na.omit(LINK_ID_OTHERS))), 
    # Farms
    `Farms` = length(unique(na.omit(PRO_ID))), 
    `Villages` = length(unique(na.omit(PRO_VILLAGE_NAME))), 
    # Buyers
    Buyers = length(unique(na.omit(BUYER_ID))),
    `IC2B coops` = length(unique(na.omit(LINK_ACTUAL_COOP_ID))),
    `IC2B buying stations` = length(unique(na.omit(LINK_ACTUAL_COOP_BS_ID))),
    `Not coops` = length(unique(na.omit(if_else(!BUYER_IS_COOP, BUYER_ID, NA))))
    
    )


```

### Features 
With differences between actual and/virtual in development. 
Alternatively, we could look at: 
- Only in actual 
- Only in all (potential)

```{r}
names(stg2_development)
stg2_features_tobalance_1 =
  stg2_development %>%
  mutate(across(where(is.logical), as.integer)) %>% 
  select(LINK_IS_ACTUAL_COOP_class, 
         LINK_DISTANCE_METERS,
         LINK_IS_WITH_1_NEAREST_COOPS,
         LINK_IS_WITH_5_NEAREST_COOPS,
         CELL_N_BS_WITHIN_DIST,
         CELL_N_COOP_IN_DPT, CELL_AVG_N_LICBUY_IN_DPT,
         CELL_COCOA_HA, CELL_SETTLEMENT_HA, CELL_IMPOSSIBLE_HA, CELL_TRI_MM)

datasummary_balance(~LINK_IS_ACTUAL_COOP_class, 
                    data = stg2_features_tobalance_1, 
                    output = here("outputs", "input_data_descriptives", paste0("stg2_",MODEL_RESOLUTION_KM,"km_features.png")))

stg2_features_tobalance_2 =
  stg2_development %>%
  mutate(across(where(is.logical), as.integer)) %>% 
  select(LINK_IS_ACTUAL_COOP_class,
         COOP_FARMERS, 
         COOP_N_KNOWN_BUYERS, COOP_N_KNOWN_BS,
         starts_with("COOP_STATUS_"), 
         COOP_CERTIFIED, COOP_RFA, COOP_UTZ, COOP_FT, 
         COOP_HAS_SSI, starts_with("COOP_SSI_"), 
         starts_with("COOP_BS_10KM_"))

datasummary_balance(~LINK_IS_ACTUAL_COOP_class, 
                    data = stg2_features_tobalance_2)

```

### Map of actual links
```{r}

```



# FIRST STAGE 

## Formula
```{r}
anyNA(stg1_development)
# names(cells)
# anyNA(cells)

stg1_allfeatures = 
  cells %>% 
  select(
    #CELL_COCOA_HA,
    # CELL_DENSEFOREST_HA
    # CELL_OTHERFORESTS_HA
    # CELL_COFFEE_HA,
    # CELL_RUBBER_HA,
    # CELL_PALM_HA,
    # CELL_COCONUT_HA,
    # CELL_CASHEW_HA,
    # CELL_OTHERAG_HA,
    # CELL_SETTLEMENT_HA,
    # CELL_IMPOSSIBLE_HA,
    # CELL_SETTLEMENT_HA,
    CELL_TRI_MM,
    CELL_N_BS_WITHIN_DIST, CELL_N_COOP_IN_DPT, CELL_MIN_DISTANCE_METERS,
    # Include coop-level features summarised at the 1 nearest, the 5 nearest and the whole-coop levels. 
    # This increases the simple fit performance from an OOB R2 of .17 (with only summaries at 5 nearest coop-level) to .24
    starts_with("CELL_PROP_"), -CELL_PROP_VOLUME_COOPS, -CELL_PROP_VOLUME_OTHERS,
    starts_with("CELL_AVG_"), CELL_AVG_N_LICBUY_IN_DPT, CELL_AVG_DISTANCE_METERS_5_NEAREST_COOPS,
    # -ends_with("_HA"), 
    starts_with("CELL_COUNT_")) %>%
  names()  
  
# Restricted list of more exogenous features regarding the further applications of the model. 
# This excludes SSI and certification related variables, and LU (except settlement) in coop buffers.  
stg1_exofeatures = 
  stg1_allfeatures %>% 
  grep(~., pattern = "DISTANCE|N_BS_WITHIN|N_KNOWN_BS|N_COOP_IN|LICBUY|STATUS|_TRI|SETTLEMENT|COOP_FARMERS$", 
       value = TRUE) %>% 
  unique()

stg1_formula_allfeatures = as.formula(paste0("CELL_PROP_VOLUME_COOPS ~ ", paste0(stg1_allfeatures, collapse = " + ")))
stg1_mformula_exofeatures = as.formula(paste0("CELL_PROP_VOLUME_COOPS ~ ", paste0(stg1_exofeatures, collapse = " + ")))

```

The first stage has `r length(stg1_allfeatures)` potential features, `r length(stg1_exofeatures)` of which are exogenous to further applications. 

## Simple fit 
This is simple because it does not do feature selection nor optimize hyper-parameters.
```{r}
stg1_mfit = ranger(data = stg1_development, 
                   importance = 'permutation',
                   case.weights = "CELL_REPRESENTATIVITY_STD_WEIGHT",
                   formula = stg1_formula_allfeatures, 
                   seed = 8888
                   )
print(stg1_mfit)

stg1_mfit = ranger(data = stg1_development, 
                   importance = 'permutation',
                   case.weights = "CELL_REPRESENTATIVITY_STD_WEIGHT",
                   formula = stg1_mformula_exofeatures, 
                   seed = 8888
                   )
print(stg1_mfit)

```

## Model development
Doing feature ranking and hyper-parameter optimization
This is the model development. 

This is all handled by package familiar. 

For warm starts: 
precompute_data_assignment --> An experimentData object.
precompute_feature_info    --> An experimentData object.
precompute_vimp            --> An experimentData object.
(each does additional steps)

predict function like anywhere else. 
```{r}
# ?train_familiar
# ?theme_familiar
# ?summon_familiar
# ?as_familiar_data
# ?predict  

anyNA(stg1_development)

# Repository for familiar 1st stage 
# summon_familiar writes all it does in a repo. It returns nothing here.  
stage1_model_repo = here("temp_data", "familiar", "stage_1")

# Experimental design 
exp_design = "bt(fs+mb,200)"

summon_familiar(
  
  formula = stg1_formula_allfeatures,
  data = stg1_development,
  experiment_dir = stage1_model_repo,
  sample_id_column = "CELL_ID",
  outcome_name = "Cooperative outlet share",
  outcome_column = "CELL_PROP_VOLUME_COOPS",
  outcome_type = "continuous",
  experimental_design = exp_design, #"fs + mb", #  # "cv(bt(fs,100) + mb, 3)",
  
  # Use bt because we have many features compared to the number of observations.  "The most practical application of bt is for repeating feature selection multiple times (e.g. bt(fs,50)+mb+ev), as this allows for aggregating variable importance and reducing the effect of random selection."

  # imbalance_correction_method = "random_undersampling", # do not specify, to avoid any kind of under-sampling, since we did it in external pre-processing.  
  parallel = TRUE, # The default is TRUE, but unnecessary in 1st stage at least. Actually it IS! 
  parallel_nr_cores = detectCores() - 2, # 2 is the default, and UCLouvain machine has 8, in case we need to increase. 
  
  # PRE-PROCESSING ARGS
  # (not all "none" are the defaults)
  filter_method = "none", # no feature to be filtered in pre-processing
  transformation_method = "none", 
  normalisation_method = "none",
  cluster_method = "hclust", # the default. This is categorised in data processing, but it will affect feature selection. 
  # imputation_method does not matter bc we have no NA. 
  
  # FEATURE SELECTION & OPTIMIZATION 
  fs_method = "random_forest_ranger_permutation", # see https://cran.r-project.org/web/packages/familiar/vignettes/feature_selection_precompiled.html
  # fs_method_parameter = list("random_forest_ranger_permutation" = list()), # this would need to have this format, but let it unspecified, so that feature selection optimizes on ALL hyper-parameters. 
  # vimp_aggregation_method = "borda", # borda is the default. Check guidance to depart. 
  
  learner = "random_forest_ranger",
  # hyperparameter = list("ranger" = list()), #  "If no parameters are provided, sequential model-based optimisation is used to determine optimal hyperparameters."
  
  # EVALUATION INFERENCE
  # The default is "bootstrap_confidence_interval" or "bci", so we have to tell the model to do just quick point estimates where we don't care much about inference. Especially as bci can easily be queried in post-processing.  
  estimation_type = list("prediction_data" = "bci", "model_performance"="bci", 
                         "permutation_vimp" = "point", 
                         "ice_data"= "point", 
                         "auc_data" = "point", 
                         "decision_curve_analyis" = "point"), 
  confidence_level = 0.95, # the default. 
  detail_level = "hybrid" # the default. See ?summon_familiar and  https://cran.r-project.org/web/packages/familiar/vignettes/evaluation_and_explanation_precompiled.html
)




# --------------------- Finders of familiar outputs ---------------------

# Feature info - this gives generic info about the features in the model 
# feature_info = readRDS(here(stage1_model_repo, "20241127134237_feature_info.RDS"))

# Iterations - this gives info about the structure of the sampling applied by the experimental design. 
# iterations = readRDS(here(stage1_model_repo, "20241125194101_iterations.RDS"))

# Model development results - to report model performance
stage1_results = here(stage1_model_repo, "results", "pooled_data")

# Models - to run predictions
stage1_model_path = here(stage1_model_repo, 
                         "trained_models", 
                         "random_forest_ranger", 
                         "random_forest_ranger_permutation")

# Select the model/ensemble we want to work with 
stage1_ensemble_names = list.files(stage1_model_path, pattern = "ensemble")

model_date = gsub("-", "", today()) # replace by yyyymmdd as needed
model1_name = 
  stage1_ensemble_names %>% 
  grep(~.,  
       pattern = model_date, 
       value = TRUE) # take the first one in case there are several
                                          
model1 = readRDS(here(stage1_model_path, model1_name))

```

## Performance
```{r}
# Performance metrics are stored here
perf_metrics = read.csv2(here(stage1_results, "performance", "performance_metric.csv"))

perf_metrics


# Normalement ces plots sont déjà exportés automatiquement par summon_familiar. 
plot_perf_model1 = 
  familiar::plot_model_performance(
  object = model1,
  draw = TRUE,
  facet_by = "metric",
  data = stg1_development,
  estimation_type = "bci",
  metric = c("mse", "rmse", "rse", "rrse", "explained_variance", "r2_score"))

# Save plot
plot_perf_model1
ggsave(
  filename = paste0(object_name(stg1_formula_allfeatures), "_", gsub(",","_",exp_design), ".png"),
  path = here("outputs", "familiar", "stage_1", "performance"))

```


## Feature importance & explanation
Importance ranks features wrt. each other but cannot tell direction or magnitude. 
Explanation is produced by feature, and can be interpreted in target scale. 

### Feature importance
```{r}
importance_repo = here(stage1_results, "variable_importance")

# These summon_familiar outputs are not yet aggregated, they are bootstrap-specific lists of ranked features used in model development.  
# stage1_vimp = here(stage1_model_repo, "variable_importance")
# vimp = readRDS(here(stage1_vimp, "20241127134237_fs_random_forest_ranger_permutation.RDS"))
# vimp_hp = readRDS(here(stage1_vimp, "random_forest_ranger", "20241127134237_hyperparameters_random_forest_ranger_1_1.RDS"))


# The plot_model_signature_occurrence method plots the occurrence of features among the first 5 ranks across an ensemble of models (if available). The rank threshold can be specified using the rank_threshold argument or the eval_aggregation_rank_threshold parameter (summon_familiar).

```

### Explanation
Here we use Individual Conditional Expectation (ICE) and Partial Dependence (PD) plots
```{r}
explanation_repo = here(stage1_results, "explanation")



```


# SECOND STAGE 

## Formula
```{r}
# names(stg2_development)
anyNA(stg2_development)

stg2_allfeatures = 
  stg2_development %>% 
  select(
    ends_with("_HA"), CELL_TRI_MM, 
    CELL_N_BS_WITHIN_DIST, # CELL_N_COOP_IN_DPT, CELL_AVG_N_LICBUY_IN_DPT,
    # CELL_AVG_DISTANCE_METERS_5_NEAREST_COOPS, CELL_MIN_DISTANCE_METERS,
    LINK_DISTANCE_METERS,
    starts_with("COOP_FARMERS"), 
    COOP_N_KNOWN_BUYERS, COOP_N_KNOWN_BS,
    COOP_RFA, COOP_UTZ, COOP_FT,
    starts_with("COOP_CERTIFIED"), 
    COOP_HAS_SSI, 
    starts_with("COOP_SSI_"), 
    starts_with("COOP_DISTRICT_"), -COOP_DISTRICT_NAME,
    starts_with("COOP_STATUS_"), 
    starts_with("COOP_BS_10KM")
    ) %>% 
  names() 
  
grep("'", stg2_allfeatures, value = T)

stg2_formula_allfeatures = as.formula(paste0("LINK_IS_ACTUAL_COOP_class ~ ", paste0(stg2_allfeatures, collapse = " + ")))


```

## Model development 
```{r}

stg2_mfit =
  boost_tree(
    mode = "classification",
    mtry = 6,
    trees = 5,
    min_n = 5
  ) %>%
  fit(data = stg2_training,
      formula = stg2_formula_allfeatures)

# stg2mfit = 
#   xgboost(
#   label = stg2_training %>% select(LINK_IS_ACTUAL_COOP_class) %>% as.matrix(), 
#   data = stg2_training %>% select(-LINK_IS_ACTUAL_COOP_class), 
#   nrounds = 6
# )


```

## Performance 
```{r}
(test_pred_prob <- predict(stg2_mfit, 
                             new_data=stg2_test, 
                             type = "prob"))

stg2_test$LINK_PRED_ACTUAL_COOP_prob = test_pred_prob$`.pred_Actual links`


(test_pred_class <- predict(stg2_mfit, 
                             new_data=stg2_test, 
                             type = "class")) # this implements a 50% threshold, 
# i.e., if the predicted link is more likely to exist than to not exist, the prediction is classified as "Actual link" 
stg2_test$LINK_PRED_ACTUAL_COOP_class = test_pred_class$.pred_class

stg2_test = 
  stg2_test %>% 
  mutate(TP = LINK_PRED_ACTUAL_COOP_class == "Actual links"  & LINK_IS_ACTUAL_COOP_class == "Actual links",
         TN = LINK_PRED_ACTUAL_COOP_class == "Virtual links" & LINK_IS_ACTUAL_COOP_class == "Virtual links",
         FP = LINK_PRED_ACTUAL_COOP_class == "Actual links"  & LINK_IS_ACTUAL_COOP_class == "Virtual links",
         FN = LINK_PRED_ACTUAL_COOP_class == "Virtual links" & LINK_IS_ACTUAL_COOP_class == "Actual links")


```

### Accuracy 
we can calculate the overall accuracy score as a sum of instances where predicted and actual classes match divided by the total number of rows:
```{r}

(accuracy = sum(stg2_test$LINK_PRED_ACTUAL_COOP_class == stg2_test$LINK_IS_ACTUAL_COOP_class) / nrow(stg2_test))
(accuracy = (sum(stg2_test$TP) + sum(stg2_test$TN) ) / (sum(stg2_test$TP) + sum(stg2_test$TN)  + sum(stg2_test$FP) + sum(stg2_test$FN)))

```

### True Positive Rate (Recall) 
```{r}
(recall = sum(stg2_test$TP) / (sum(stg2_test$TP) + sum(stg2_test$FN)))
```

### False Negative Rate (probability of false alarm)
```{r}
(fpr = sum(stg2_test$FP) / (sum(stg2_test$TN) + sum(stg2_test$FP)))
```

### Precision
```{r}
(precision = sum(stg2_test$TP) / (sum(stg2_test$TP) + sum(stg2_test$FP)))

```


### Confusion Matrix  
```{r}
# This requires package caret which fails to install. 
# cm = confusionMatrix(stg2_test$LINK_IS_ACTUAL_COOP_class, stg2_test$LINK_PRED_ACTUAL_COOP_class)
# 
# 
# # Plot it 
# cfm <- as_tibble(cm$table)
# plot_confusion_matrix(cfm, target_col = "Reference", prediction_col = "Prediction", counts_col = "n")

```

### PR-AUC
```{r}
prc_xgboost_test = 
  pr_curve(
    data = stg2_test, 
    truth = LINK_IS_ACTUAL_COOP_class,
    LINK_PRED_ACTUAL_COOP_prob, 
    event_level = "second"
)

(PRAUC = 
  pr_auc(
    data = stg2_test, 
    truth = LINK_IS_ACTUAL_COOP_class,
    LINK_PRED_ACTUAL_COOP_prob, 
    event_level = "second",
    estimator = "binary"
))

ggplot(prc_xgboost_test, aes(x = recall, y = precision)) +
  geom_path() +
  coord_equal() +
  theme_bw()  
  # legend(legend = c(paste0("Main model \nAUC = ",round(PRAUC, 2))))
  
```

### AUROC
```{r}
roc_xgboost_test = 
  roc(
  data = stg2_test, 
  response = LINK_IS_ACTUAL_COOP_class,
  predictor = LINK_PRED_ACTUAL_COOP_prob,
  quiet = TRUE
)

(AUC = roc_xgboost_test$auc)

plot(pROC::smooth(roc_xgboost_test), col = "blue", lwd = 1) 
legend(
  "bottomright",
  col = "blue",
  lwd = 1,
  legend = c(paste0("Main model \nAUC = ",round(AUC, 2)))
)
```



# PREDICTION
Here, we build the prediction setS for each stage. 
First, based on LU in cells. 
Second, based on AoA of 1st stage model. 
Moreover, we report here on the Novelty of cells and links in (and out of) the prediction sets. 

## LU discarding
```{r}

```


## AoA
```{r}


```



## Novelty
```{r}
# Novelty in development data 
devdat_prediction_1 = read.csv(here(stage1_results, "prediction", "prediction.csv"))
devdat_prediction_2 = read.csv(here(stage2_results, "prediction", "prediction.csv"))



```

## Prediction sets
```{r}

```



## Predict
```{r}
model1_prediction = predict(model1, newdata = stg1_prediction_set)
saveRDS(model1_prediction, 
        here("temp_data", ""))

stg2_prediction$CELL_PRED_PROP_VOLUME_COOPS = predict(model2, newdata = stg2_prediction)$predictions

```


















## Prediction (deprecated)
## Simple predict (deprecated)
```{r}
stg1_predict = 
  cells %>% 
  filter(!CELL_NO_POTENTIAL_LINK)


stg1_predict$CELL_PRED_PROP_VOLUME_COOPS = predict(stg1_mfit, data=stg1_predict)$predictions

stg1_predict$CELL_PRED_PROP_VOLUME_COOPS %>% summary()

cells = 
  cells %>% 
  left_join(stg1_predict %>% select(CELL_ID, CELL_PRED_PROP_VOLUME_COOPS), 
            by = "CELL_ID") %>% 
  # this left NAs in cells not in the predict set, i.e. in the development set
  mutate(CELL_PRED_PROP_VOLUME_COOPS = case_when(
    is.na(CELL_PRED_PROP_VOLUME_COOPS) ~ CELL_PROP_VOLUME_COOPS, 
    TRUE ~ CELL_PRED_PROP_VOLUME_COOPS
  ))

cells$CELL_PRED_PROP_VOLUME_COOPS %>% summary()

# at this stage, the NAs come from CELL_PROP_VOLUME_COOPS, in cells with no potential link at all 
stopifnot(cells %>% filter(is.na(CELL_PRED_PROP_VOLUME_COOPS)) %>% pull(CELL_NO_POTENTIAL_LINK) %>% all())

```

- TAKES TOO MUCH TIME, check how to improve efficiency 
```{r}
stg2_predict = links

stg2_predict$LINK_PRED_EXIST_PROB = predict(stg2_mfit, 
                                            new_data=stg2_predict, 
                                            type = "prob")$`.pred_Actual links`
  

stg2_predict$LINK_PRED_EXIST_PROB %>% summary()

cells = 
  cells %>% 
  left_join(stg2_predict %>% select(CELL_ID, CELL_PRED_PROP_VOLUME_COOPS), 
            by = "CELL_ID") %>% 
  # this left NAs in cells not in the predict set, i.e. in the development set
  mutate(CELL_PRED_PROP_VOLUME_COOPS = case_when(
    is.na(CELL_PRED_PROP_VOLUME_COOPS) ~ CELL_PROP_VOLUME_COOPS, 
    TRUE ~ CELL_PRED_PROP_VOLUME_COOPS
  ))

cells$CELL_PRED_PROP_VOLUME_COOPS %>% summary()

# at this stage, the NAs come from CELL_PROP_VOLUME_COOPS, in cells with no potential link at all 
stopifnot(cells %>% filter(is.na(CELL_PRED_PROP_VOLUME_COOPS)) %>% pull(CELL_NO_POTENTIAL_LINK) %>% all())






```